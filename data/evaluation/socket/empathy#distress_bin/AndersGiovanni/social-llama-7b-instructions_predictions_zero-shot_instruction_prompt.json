[
    {
        "idx": 0,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. Label it as 'not distress' if the text does not convey distressing or negative emotions. Label it as 'distress bin' if the text contains distressing or negative emotions such as anger, frustration, or agitation.\nInput: I thought the article was quite sad to read and disheartening to hear about the Iraqi people. I felt sad for them knowing their future was uncertain and how hard it was to find a job. The economy they deal with is much worse than ours and I can only imagine how difficult it must be living there. I hope that it gets better in the future.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress but sympathetic and saddened by the situation of the Iraqi people",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 1,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either \"not distress\" or \"distress bin\" based on the content. Assign the label \"not distress\" to texts that display no signs of distress or emotional discomfort, and the label \"distress bin\" to texts that contain elements of distress or emotional unease.\nInput: I think almost everyone has an opinion on Hilary Clinton over Donald Trump. Many didn't expect Donald to win the election but here we are. So many political scandals unfolded and more continuing to unravel. Many didn't agree with Hilary from the Bengazi investigation and many didn't agree with Trump, but in the end that's just politics.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but not distress bin either. Not distress bin but not distress bin either. Some people may have mixed feelings or not distress but not distress bin either. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress bin not distress bin. Not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 2,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of the two categories - 'not distress' or 'distress bin'. Texts that contain distressing or concerning information should be labeled as 'distress bin', while texts that do not convey distress should be labeled as 'not distress'.\nInput: I've heard of necrotizing fasciitis before. It's really fucking scary to think that just from a tiny little cut you could get a disease that has a high likelihood of killing you. There's also a similar bacteria called naegleria fowlerii that can get into your body from water going up your nostrils and it basically eats your brain. Nature is fucking metal.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "biomedical danger, biophysical danger, biological hazard, biomedical risk, biological threat, biomedical danger biology, biomedical biophysical biology, biomedical biological biome, biomedical biophysical biomedicine biomedical biophysical biology biomedical biophysical biome biomedical biophysical biology biomedical biophysical biome biomedical biophysical biology biomedical biophysical biome biomedical biophysical biology biomedical biophysical biome biomedical biophysical biology biomedical biophysical",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 3,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either \"not distress\" or \"distress bin\" based on the content. Assign the label \"not distress\" when the text does not convey distressing or emotional content. Assign the label \"distress bin\" when the text expresses distress, emotional pain, or suffering.\nInput: It's a shame that we have so many random acts of violence in this country.  It seems every other week we have some massacre involving either guns, a right wing extremist or a muslim extremist.  I think what they have in common are either mentally ill people or people who are extremist in their world views and religion.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern about violence and social issues] not distress but concern about violence and social issues",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 4,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it contains expressions of distress or not. Assign the label 'not distress' if the input does not contain distressing language or sentiments related to personal anguish, anxiety, or worry. Otherwise, assign the label 'distress bin' if the input conveys distress or emotional turmoil.\nInput: I feel for her. They couldnâ€™t afford to cremate them on their own and help them, and the financial help they were entitled to as crime victims had not come through because the system today isn't going to help criminals. I hope the government now helps criminals through dangerous activities and make the world a better place\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but empathy for the situation and hope for positive change",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 5,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into 'not distress' or 'distress bin'. Assign the label 'not distress' if the input conveys curiosity, questions, or is not indicative of any distress. Assign the label 'distress bin' if the input expresses anxiety, urgency, or distress.\nInput: Here's an article about crazed person who murdered two unfortunate women overseas. Life is crazy. I can't imagine what the families are going through. Having to go to or being forced into sex work is bad enough, but for it to end like this is just sad. It feels like there's no place safe in this world to be a woman sometimes.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but rather sympathy and sadness for the victims and their families",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 6,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on distress level related to climate change. Assign the label 'not distress' to texts that discuss climate change without indicating distress or negative implications. Assign the label 'distress bin' to texts that highlight distress, negative effects, or implications caused by climate change.\nInput: I know this article is super wordy, but it is an interesting read, if you have a chance ad you are bored, make sure you read it. It is about how Democrats will move forward in the next few years to get legoslation moving. It has been hard with Trump in the White House for the whole country, but imagine being a democrat right now trying to push legislation that your constituents are asking about? What a time to be alive! We should all just try to make the country a lot better right now!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but motivated and hopeful tone about the political efforts to address climate change and other issues. No distress in this text, just a sense of hope and urgency to make progress on important issues.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 7,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress it conveys. The labels are as follows:\n- 'not distress': the text does not convey distress or negative emotions.\n- 'distress bin': the text conveys distress or negative emotions.\nInput: Reading about issues happening across the world seems foreign, but just think: any trouble anywhere in the world, the US is usually involved. I think any conflict and abuses of power in any nation in the world, especially in the middle east, can spell disaster for the people in the US. We can't really ignore issues that happen far away because ultimately as a nation, we will have to face the consequences, either by sending our troops or  any other effects.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress, but concerned about the potential consequences of global issues.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 8,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Create a text classification model for identifying distress-related content. Assign the label 'distress bin' to textual inputs that express emotions like sadness, hopelessness, and concern for humanitarian causes. Assign the label 'not distress' to texts that do not convey distress or emotional turmoil.\nInput: That's incredibly disgusting. I feel like it should count as a hate crime, and everyone on that boat who had anything to do with that incident should be brought before a judge and made to answer for their involvement. I really hope the LGBT community organizes some kind of boycott; Royal Caribbean should be made to feel financial pain for their negligence\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " angry and distressed response to a recent event, with a call to action to take action against the perpetrators and those involved in the incident. The use of strong language like \"incredibly disgusting\" and \"hate crime\" indicates a high level of emotional upset and outrage. The call to action is also a form of distress and mobilization, as it is a call to take collective action to address the injustice. This text is likely to be classified under distress bin, as it is a response to a traumatic event and a call to action to address it.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 9,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the levels of distress expressed. Determine if the text falls into the 'not distress' category if the content does not convey distress or the 'distress bin' category if distress is evident in the text.\nInput: This is terrible, but what I find hard to believe is that there are still that many Yahoo accounts in the world that aren't spambots. Or some other kind of bots. Anyway, aren't you glad I got you on gmail? I'm glad I shut my yahoo account down a long time ago. You should probably do that, if you haven't, just for safety's sake.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but somewhat annoyed or worried about Yahoo accounts still being used",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 10,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - \"not distress\" and \"distress bin\". The output label will be \"not distress\" if the text does not convey distressing emotions or content. In cases where the text does convey distressing emotions or content, assign the label \"distress bin\" to indicate the presence of distress.\nInput: I just read an article about America's refugee problem, that talked about the Somali community in Minneapolis. I can't believe the emotional language they tried to use in the article; it just makes me sick to see any reporting that doesn't only concern the facts, with no editorializing by the author. I wish that everyone who decided to become a writer would learn that there is no place for opinion in the news.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but perhaps some frustration or irritation, but not distress] not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 11,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it conveys distress or not-distress sentiments. Assign the label 'not distress' if the text expresses positive emotions, enthusiasm, or informative content. Assign the label 'distress bin' if the text shows signs of distress, negative sentiments, or troubling thoughts.\nInput: Apparently another Christian was murdered in a Muslim land, and the excuse was that he blasphemed, when he had really just shared an anti-ISIS cartoon. It is no wonder that religious minorities in Syria supported Assad. At least he protects them. He probably has committed atrocities, but it seems every side has committed atrocities there.  This murder was in Jordan, and even though the Jordanian royals come off as urbane Westerners, there is obviously an undercurrent of extreme Islamism in some of the population. Christians are murdered all the time around the world, but this rarely gets attention in the US media, which is completely corrupt.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but concern and alarm about the violence and persecution of religious minorities in the Middle East, particularly Christians, and the lack of attention to their plight in the media",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 12,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into \"not distress\" or \"distress bin\" categories. The label \"not distress\" should be assigned when the text does not contain distressing or negative elements, while the label \"distress bin\" should be assigned when the text includes distressing or negative content such as arrest, lying, escaping a war-ravaged country, or being under difficult circumstances.\nInput: The whole \"police violence against blacks\" theme has been overplayed to manipulate people. The fact is that there really is a problem of police feeling justified in shooting people whenever they feel threatened, but this doesn't just happen to blacks. I can think of four cases off the top of my head where innocent unarmed white men were killed by police. One of them was the recent case where the guy who died was the victim of \"swatting\". He wasn't involved in an crime at all, but the police burst into his house with guns blazing and he died. And the cop won't be prosecuted. I hope that blacks who care about this issue will realize they are being manipulated and will join forces with others who don't want to live in a police state.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but rather a biased and potentially harmful perspective on the issue of police violence against black people. The statement implies that the issue is not a legitimate one, and that it is being used as a \"trump card\" or a way to manipulate people. It also downplays the experiences of black people who have been victims of police violence, and suggests that the media is not reporting the whole story. The not distress but rather not caring or not listening perspective. not distress, but not caring about the issues that matter to black people. not distress, but not caring about their experiences and perspectives. not distress, but not willing to listen to their voices or take their concerns",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 13,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify whether the text expresses distress or not based on the given labels. \n- 'not distress': Indicates that the text does not convey any distress or negative emotional response.\n- 'distress bin': Indicates that the text conveys distress, worry, or negative emotions.\nInput: Funny how it always comes down the to the gun and not the person wielding it. People will always be able to get guns, legally or not. the issue is more with society treatment of young men. Too many single moms, too many kids being ostracized and bullied. But yeah, that's the gun's fault. i don't own a gun, but I'd be damned if I gave one up to those liberal fascists.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " irony, anger, and frustration but not distress or despair] irony, anger, and frustration but no distress or despair] irony, anger, and frustration but no distress or despair",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 14,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as 'distress bin' if the text reports a distressing or alarming situation, otherwise classify it as 'not distress'.\nInput: Are you aware that only certain refuges are helped and accepted?  I can't imagine the heart break that they endure traveling so far thinking they are safe to be turned around and denied.  The whole system is so flawed.  There is no appropriate help for these people!  They have so many unfair hurdles to go through.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 15,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into one of the two categories: 'not distress' or 'distress bin'. The text should be labeled as 'distress bin' if it contains content that describes or alludes to distressing or concerning topics, situations, or emotions. Conversely, label the text as 'not distress' if it does not contain any distressing content.\nInput: Poor woman!  I hope that she is able to recover.  I hate to hear of anyone being in an accident.  I see that there were three cars involved.  I wonder if she was the other one critically injured.  I guess if there were were at least three people involved and only one was seriously injured, those aren't the worst odds.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 16,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of the two categories: 'not distress' or 'distress bin'. Assign the label 'not distress' if the text does not contain distressed or negative sentiments. Assign the label 'distress bin' if the text expresses distress, negativity, or pessimism about societal issues or the state of the world. In this case, based on the provided input, assign the output label as 'not distress'.\nInput: So apparently sea ice is becoming less and less which is a concern four our environment and all I can think of is how it will affect the animals in the ocean.  This cannot be good for the ecosystem.  Or is it? In contrast to the article, i remember seeing a whale die because the ice was so thick and they were trapped. Perhaps neither are good, but how do we fix this?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 17,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text into 'distress bin' if it expresses distress, sadness, or hopelessness, otherwise label it as 'not distress'.\nInput: This is so sad.  Today I read about a lady who passed away November 6th and had shared many of her stories of her experiences in the holocaust.  IT's very sad to think there aren't many people left to share these stories.  I remember being in Junior high and hearing someone speak about it, and to think kids these days will never get that.  Thankfully, there are museums for people to attend to hear and get closer to what truly happened back then.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Sadness",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 18,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into 'not distress' or 'distress bin'. 'not distress' indicates the text does not contain distressing content, while 'distress bin' signifies the presence of distressing elements in the text such as violence, tragedy, or negative emotional experiences.\nInput: The first article never appeared, there was only a generic place holders and nothing to write about. I answered questions about my emotions based on how I feel right now and I'm writing this to explain that the article wasn't there. I hope that the following articles will appear and I'll be able to finish this survey as intended.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but a bit disappointed or frustrated about the absence of the article] not distress but a bit disappointed or frustrated about the absence of the article. Not distressed but a little bit annoyed or disappointed.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 19,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on emotions expressed into two categories - 'not distress' for content that does not indicate distress or worry, and 'distress bin' for content that conveys distress, fear, or concern.\nInput: It's such a shame that so much violence takes place over there each year. You'd think all the different factions would finally agree to disagree and move on but instead they just seem to want to keep killing. I understand why since so many different groups want to destroy the other side leaving smaller nations like Yemen to have to defend themselves since the other factions seem to be unable to leave in peace.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness for the suffering caused by violence, but also frustration and concern about the ongoing cycle of conflict and lack of resolution.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 20,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the sentiment or emotional response conveyed. Assign the label 'not distress' if the text does not express distress, sadness, or negative emotions, and assign the label 'distress bin' if the text depicts distress, sadness, or negative emotions.\nInput: Overall the problem here seems to be that overuse of resources in a certain area needs to be stopped. Simply pumping more water isn't the issue and perhaps the fact that too many people are trying to use that water source should be something that's looked into. There should also be some sort of testing and filtering system put into place to protect the people.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, not distressed but also not happy but not upset either, just a neutral problem-solving suggestion",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 21,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text based on the labels ['not distress', 'distress bin']. Choose the label that best represents the emotional distress level or content mentioned in the input text.\nInput: This article greatly disturbs me. The fact that we treat Muslims and people of their culture like dogs and terrorist is disgusting and wrong both morally and ethically. The way they are being shown on tv and media is wrong and horrible. Our president thinks that if we ban muslims from the country, all of a sudden our nation is safe. When the fact of the matter is, most shootings that happen in this country, are from Caucasians. Muslims are shown in bad light due to some extremist and they do not deserve this treatment.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress and outrage] distaste, indignation, and wrongdoing towards Muslims and their treatment in the media and by the president, and towards the unfair and discriminatory actions towards them. The use of the term \"dog\" as a metaphor for Muslims is offensive and dehumanizing, and the generalization that all Muslims are terrorists is a stereotype and a misconception. The article and the media coverage of Muslims is unfair and biased, and it perpetuates harmful stereotypes and prejudices. The treatment of Muslims is wrong both morally and ethically, and it is important to stand up against discrimination and prejud",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 22,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the labels ['not distress', 'distress bin'].\nInput: Can you imagine being forced to live in such a violent place?? A place where your life is at risk all day everyday? These poor people have learned to live in extreme fear everyday. Imagine purposely bringing babies into the world when this is happening where you live. I wouldn't do it, I would never on purpose bring another life into this kind of situation. God bless these poor souls.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin, compassion bin, empathy bin, sadness bin, sympathy bin, pity bin, compassion bin, distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 23,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. The label 'not distress' should be assigned when the text does not express any emotional distress or troubling feelings, and 'distress bin' should be assigned when the text conveys distress, unease, or emotional discomfort.\nInput: Venezuela and many of it's sister countries are going through a crisis. Due to drops in oil prices, and the loss of income the country has received from this drop, the citizens are the ones that are paying for it. They are hungry, there is issues with people not having enough food and starving. Their political powers are corrupt and can't be counted on for help. There is fighting, rebels and rampant crime. My heart breaks for this people, as they don't have anyone to turn to for help. They feel powerless, hungry and scared.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and distress for the people of Venezuela and surrounding countries affected by the crisis",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 24,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input into one of two categories, 'not distress' or 'distress bin'. 'Not distress' refers to content that does not convey distress or emotional impact, while 'distress bin' indicates text that contains distressing or emotionally impactful content.\nInput: As we all know, there has been much media on police brutality. There are many police officers that believe they are above the law, and the common citizens doesn't have any rights when they are interacting with them. Unfortunately, it's very sad to say, that even if a citizen is innocent, if they don't cooperate to the fullest, the police can physically harm them, even possibly lead to being shot and killed. This is very scary! So, while I don't believe all officers are like this, one is too many!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin, alarm and sadness about police brutality and the danger to innocent civilians at the hands of some police officers.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 25,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either \"distress bin\" or \"not distress\" based on the content. In this context, the label \"distress bin\" should be assigned to texts expressing feelings of sadness, frustration, or concern, while \"not distress\" should be applied to texts that do not convey negative emotions or distress.\nInput: Wow. So... I sure as fuck do not have that much to say about that stupid article / news story. But, I guess that I'll try to think of something. It's also not at all something that I would share or want to share with anyone that I know. It's not relevant to me or the people that I know and care about. It's not something that I would just choose to read either. Ok. Have you seen this article about the dad that killed his daughter's molester? Apparently she was molested when she was young, the guy went to jail for a year and a half and was let out. Many years later, the dad went and shot the guy. That's pretty much it. I don't know why I'm sending this to you, but what do you think? I think that it was boring and I wasn't interested in it at all.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but possibly empathy or a strong reaction to the story, but not distress bin",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 26,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the presence of distressing content into the categories 'not distress' and 'distress bin':\n- 'not distress': Indicates that the text does not contain any distressing content.\n- 'distress bin': Indicates that the text contains distressing content.\nInput: Again, I wouldn't share this with anyone; it's not that interesting to me or to the people that I know. Have you seen this article about the sudden rise in tiger murders by poachers? It's pretty shitty that this still goes on, but what can you do? People are going to be horrible for all kinds of reasons and nothing is going to change. What do you think about it? Did you think that this was an interesting article? What's your thoughts?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but not interesting either. Distressing about tiger murders, but not enough to share or take action. Distressing but not surprising, and not interesting enough to share or think much about. Not distressed but not happy about it either. Not distressed but not hopeful either. Not distressed but not caring enough to do anything. Not distressed but not interested enough to think about it or care about it. Not distressed but not motivated to do anything about it. Not distressed but not interested enough to care or do anything. Not distressed but not bothered enough to think about it or do anything. Not distressed but not caring enough",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 27,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - \"not distress\" and \"distress bin\". Assign the label \"distress bin\" to texts expressing deep concern, emotional distress, or sadness, while assigning the label \"not distress\" to texts that do not convey such emotions.\nInput: Hi can you believe this? We have to be very careful with this. You never know what kind of damage you can receive in your eyes from having these infections. I would never want to this to happen to me or my daughter. I will have to really take care of my our lenses from now and on to prevent any damage.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 28,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text as either 'not distress' or 'distress bin'. The label 'not distress' should be assigned when the content expresses a lack of empathy or concern towards others, and the label 'distress bin' should be assigned when the content conveys distress, worry, or emotional unease.\nInput: I feel like our police force is getting kinda out of control with its killings recently. It's all i seem to hear about on the news nowadays. They recently charged an officer who shot an unarmed black driver when he was outside his vehicle.It's like the police don't even care anymore which is really scary.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Concern about police violence and abuse of power, but also a sense of injustice and mistrust towards the authorities. The use of the word \"killing\" and \"out of control\" emphasizes the urgency and gravity of the situation. The phrase \"it's all I seem to hear about on the news nowadays\" suggests that the issue is getting a lot of attention and public attention, and the phrase \"it's really scary\" conveys a sense of fear and unease about the situation. There is a sense of injustice and mistrust towards the authorities, as the word \"not care\" implies a lack of empathy or concern towards the victims of police violence",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 29,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as distress or not distress based on the content. Assign the label 'distress bin' if the text expresses feelings of distress, pessimism, or concern, and label it as 'not distress' if the text does not convey such emotions.\nInput: This is so sad. Many of you know I use to have a lab. They are often the most sweetest, loving dogs around. I cannot imagine why someone would take out a gun and shoot one. This is another example (there seem to be countless that happen everyday) of why people should not own guns. I know some people will say it is not a person, but this is still another needless murder that occurred because of a gun.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 30,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Use a text classifier to determine whether the text expresses distress or not distress based on the content provided. \n\nLabels:\n- 'not distress': Refers to content that does not convey distress or unhappiness.\n- 'distress bin': Indicates that the content shows distress, sadness, or negativity.\nInput: It is so sad and terrible how these alternative medicine manufacturers take advantage of people. So many people believe that these things are healthier or will make them feel better than traditional medication, but clearly they just make things worse. These companies pray on uneducated people and it leads to such terrible outcomes. These people don't deserve these health problems.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distressed by the exploitation of vulnerable people by unscrupulous companies selling fake or ineffective alternative medicine products.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 31,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text as either \"not distress\" or \"distress bin\".  \nLabels: \n- \"not distress\": Indicates that the text does not contain any distressing or concerning information.  \n- \"distress bin\": Indicates that the text contains distressing or concerning content.\nInput: I absolutely hate seeing this kind of violent racism in the world. Too many people think that just because someone is different they are less worthy of life than themselves. It is honestly just terrible. It feels like we are seeing more and more of this everyday. Humans really need to come together and realize that we are all the same, and there is not reason to cause each other harm and pain such as this.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin, no distress bin but distress bin, distress about racism and violence against people of colour and minorities, no not distress but distress bin, distress over the prejudice and discrimination against people of colour and minorities, no not distress bin but distress bin, distress over the injustice and inequality, no not distress bin but distress bin, distress bin, distress over the state of the world, distress bin, distress bin, distress bin no not distress bin but distress bin distress bin distress bin no not distress bin but distress bin distress bin distress bin no not distress bin but distress bin dist",
        "prediction_processed": "not distress",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 32,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it expresses distress or not. Assign the label 'distress bin' if the text indicates distress, or 'not distress' if it does not.\nInput: This is so unfortunate for the family of this father and son. They were probably just trying to have a nice together, but did not research the area well enough or did not pay proper attention. There are so many things that could go wrong, and in this case, they all seemed to have gone wrong. I feel bad for them. The world can be pretty unforgiving.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy for the family' but not distress bin",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 33,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on its emotional tone as either 'not distress' or 'distress bin'. \n- 'not distress': Indicates content with no distressing or alarming elements.\n- 'distress bin': Denotes content containing distressing or upsetting language or topics.\nInput: i think that mr mayweather should have to pay that money back if he still has the neckless or give the neckless back to the store with a price tag like that the company could really need that money 1.4 million is alot of money for a company not to get. also we know that he has the money to pay for the neckless so im not sure why he doesnt just pay the rest of the balance and not have to go to court and pay all those fees.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but not happy either about the situation. Kind of neutral or upset but not distressed about it. Not distressed but not happy either about the situation. Neutral or upset but not distressed. Not distressed but not happy about it. Not distressed but not happy either about the situation. Not distressed but not happy about it.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 34,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into 'not distress' or 'distress bin' based on whether the text expresses a positive or neutral sentiment ('not distress') or indicates distress, confusion, or negative emotions ('distress bin').\nInput: We need to recognize that global warming is real and acknowledge our part in it. We as a globe need to take note and work together. The Great Barrier Reef is one of our planet's more amazing wonders and we need to do all we can to protect it, while the Amazon isn't doing absolutely fantastic we've improved the quality and conservation.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but urgent and important issue- urging for collective action to address global warming and protect the environment",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 35,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into one of two categories - 'not distress' or 'distress bin'. 'Not distress' refers to text that does not express distress or negative emotions, while 'distress bin' indicates text that expresses distress or negative emotions.\nInput: It's a shame that we're seeing this sort of rise in violence. It's not shock that after years of the right bullying the left into tolerating intolerance that we've come to this point. People aren't even trying to hide their racism anymore, and they're intentionally making shit worse to justify their oppressive agendas.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but concern and alarm about the rise of violence and intolerance in society. The use of strong language to describe the situation and the impact of past events on the current situation is powerful and emotional, but not overwhemingly distressing. It's a serious issue, but not distressing in the classical sense of the word. Distress bin not distress bin, but concern bin not distress bin. Not distress, but alarm and concern about the state of society.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 36,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into either 'not distress' or 'distress bin'. If the text expresses feelings of worry, sadness, or concern, assign the label 'distress bin'. If the text does not convey any distress or negative emotions, assign the label 'not distress'.\nInput: How can people take something like relationships for granted? It's infuriating that in a world where I have to fight for the right to marry the person I love and adore and want to pamper and cherish and share a life with that there are assholes out there like this with anger issues who will get in their alleged partner's face and shout. The hate is just mind blowing.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin, rant, irritation, frustration, but not distress or sadness per se. Worry and irritation about the state of society or the actions of some individuals, but not overwhelming distress or sadness.",
        "prediction_processed": "not distress",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 37,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text into one of two categories - 'not distress' or 'distress bin'. 'Not distress' should be assigned when the text does not convey any emotional distress, whereas 'distress bin' should be assigned when the text contains emotional distress or turmoil.\nInput: I think timeshares are silly and this article just confirms it. In the article it talks about how hard it is for some people to get rid of timeshares after they have them. Timeshare salesmen are so pushy when you first sign up for one I can't imagine how hard it is to get out of one. I'm just glad that I don't have a timeshare and never will. I'm sure they have some many tiny provisions in their contracts that make them really difficult to get out of successfully.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but slightly negative about timeshares",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 38,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the provided labels into 'not distress' or 'distress bin'. The output should indicate if the text falls under the 'not distress' category or the 'distress bin' category, based on the content of the input text.\nInput: This is disgusting! I wish that the international community would step up and stop these atrocities from continuing to happen. But no one in the international community seems to care. Its so sad, it is like another Rwanda is happening right in front of us but no one wants to spend the money to do anything about it because it is seen as just another third world backwater. Things need to change before the international order is completely forgotten about.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "emotionally charged, distressed but not distressed enough to be in distress bin but empathetic and urgent about the situation] not distress but distressed",
        "prediction_processed": "not distress",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 39,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the provided text as 'not distress' or 'distress bin'.\n   - 'not distress': The text does not elicit distress or concern.\n   - 'distress bin': The text contains information that may cause distress or worry to the reader.\nInput: This is horribly to read about. The sheer number of people dying every day, just trying to escape on boats, is quite alarming. Think about people from one country equaling those people dying in gang violence in major, crime ridden societies - but JUST for people attempting to escape via water. What should we do about this? Open our borders? Is it enough to simply help them get out of where they are to some place safer? Obviously this isnt exacly their fault, especially the kids. But what can we do? Will money help? Probably not. Open borders will. Bring them here and help them find a more peaceful way through thehri own lives.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but empathy and urgency for the situation, with a call to action to help those in need",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 40,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on emotional distress levels into either 'not distress' or 'distress bin'. The label 'not distress' should be assigned when the text does not express emotional distress, and the label 'distress bin' should be assigned when the text conveys feelings of worry, concern, or unease.\nInput: India Kashmir: The teenager blinded by pellets â€” Photographer Abid Bhat here describes the life of 14-year-old Insha Mushtaq, who lost vision in both her eyes after being hit by pellets in Indian-administered Kashmir. \"I just want to ask the security personnel who fired pellets at me what my fault was,\" Miss Mushtaq says, as she stands by the same window she was sitting at when pellets blinded her. She has been in and out of hospitals for the past three months in an attempt to regain her vision. Nothing has worked so far, but she remains hopeful. Ms Mushtaq says she wanted to become a doctor before losing her vision. She brings out her text books to show me, and flips the pages though she cannot read them anymore. \"I can only feel them now,\" she says tearfully\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin, but not distressed enough to be in distress bin. Distress bin is foremost when there isemotional distress, but distress bin is also used forempathy or sadness but not intense enough to be distressed bin. Distress bin here but not distress bin. Distress bin but not distressed enough to be distress bin. Distress bin, but not distressed enough to be distress bin. Distress bin, but not distressed enough to be distress bin. Distress bin, but not distressed enough to be distress bin. Distress bin, but not distressed enough to be distress bin. Distress",
        "prediction_processed": "not distress",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 41,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text as either 'not distress' or 'distress bin'. Assign the label 'not distress' if the text expresses opinions, thoughts, or concerns without expressing distress or discomfort. Assign the label 'distress bin' if the text conveys distress, uneasiness, or discomfort.\nInput: Details and information about the past is used to make decisions, as past experiences of feelings influence current decision-making, how people will feel in the future, and if they want to feel that way again. Gilbert and Wilson conducted a study to show how pleased a person would feel if they purchased flowers for themselves for no specific reason (birthday, anniversary, or promotion etc.) and how long they thought that feeling would last. People who had no experience of purchasing flowers for themselves and those who had experienced buying flowers for themselves were tested. Results showed that those who had purchased flowers in the past for themselves felt happier and that feeling lasted longer for them than for a person who had never experienced purchasing flowers for themselves\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but potentially mild positive emotions such as happiness or satisfaction but not distress.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 42,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of the two categories - 'not distress' or 'distress bin', based on the emotional tone conveyed in the text. Assign the label 'not distress' if the content does not express emotional distress or pain, and assign the label 'distress bin' if the content conveys sadness, discomfort, or sorrow.\nInput: the trumph had made a huge impact on a american politics. he had made some terrible move on the politics and it had made the other countries to trun on america.after a white supremacist carried out a massacre of black churchgoers in Charleston, S.C., it seemed as though the Confederate battle flag. these were also made some huge impact on the american politics that had made by trumph. But now that explosive and complicated vestige of the Old South is back, in a new â€” and, to some Americans, newly disturbing context. During President-elect Donald J. Trumpâ€™s campaign.When he was still running for president in June 2015, Trump was asked whether or not the Confederate flag flying above the South Carolina state house needed to be taken down. â€œI think it probably does.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin, but concern or not distress bin, not distress bin but not distress bin not distress bin not distress bin but some concern or not distress bin not distress bin not distress bin not distress bin but some concern not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not distress bin not",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 43,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it expresses distress or not. Assign the label 'distress bin' if the text indicates worry, concern, or anxiety. Assign the label 'not distress' if the text does not express distress or negative emotions.\nInput: Sleep is very important, and Iâ€™m quite sure you know that already. However, some aspects of lifeâ€“like habits, even smartphones, and stress in workâ€“affect our sleep cycles. A CDC-backed study published in February of this year has found that about a third of Americans arenâ€™t getting enough sleep.Multiple factors affect the countryâ€™s snooze patterns, and one of which is routine. Many people, researchers at the CDC say, are not prioritizing sleep.So how can you force yourself to go early in bed? Well, this new research that weâ€™ll discuss might convince you to review your priorities and put sleep above many, because you still can.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin, but rather informative and not distress bin. The text is not distressed or worried, but rather informative and Educational about the importance of sleep and the impact of various factors on sleep patterns. It also provides some tips on how to improve sleep habits, but not in a distressed or worrying manner.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 44,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it conveys distress or not. Assign the label 'distress bin' if the text contains distressing elements relating to climate change concerns, and 'not distress' if the text does not convey distress in this context.\nInput: Clearly, this was an opinion piece.  It is upsetting that so many try to pass off an opinion piece as a news article these days.  That is exactly what fake news is.  The writer wasn't even trying to hide it.  She included \"hhhhhhmmmmmmm,  hhhmmmm,  hhhmmmm\" as part of her article.  LMFAO.  That is when there was not longer any reason to take it seriously anymore.  Sure, some of the info in there may be accurate, but the bias overwhelms all.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but not impressed or distressed either] not distressed but mildly irritated or amused by the perceived biased opinion piece and biased or biased biased or biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased biased bi",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 45,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of the two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' if the text does not express emotional distress or intense negative feelings. Alternatively, label the text as 'distress bin' if it conveys emotional distress or intense negative emotions such as anger, hurt, or intensity.\nInput: The article says that- Trump to supporters harassing minorities: 'Stop it' â€” Donald Trump on Sunday told his supporters to stop harassing minorities, in his first televised sit-down interview since becoming President-elect. \"I am so saddened to hear that,\" Trump told CBS' Lesley Stahl on \"60 Minutes\" when she said Latinos and Muslims are facing harassment. \"And I say, 'Stop it.' If it -- if it helps, I will say this, and I will say right to the cameras: 'Stop it.'\" Trump directed his comments to his own supporters whom said have written racist slogans or chanted degrading messages -- particularly in schools. It was a powerful appeal to a nation ripped apart by the divisive 2016 campaign. Trump's election has left Democrats angry and many minorities fearful about the future.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but not distress bin either. Not distress but not distress bin either. The tone of not distress bin but not distress bin. Not distress but not distress bin either. Not distress bin not distress bin. Not distress bin not distress bin.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 46,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the given labels. Assign the label 'not distress' if the text does not express distress or concern, and assign the label 'distress bin' if the text conveys distress or worry.\nInput: Hello friend, how have you been lately?, I have some curiosity about an article that I read recently, that helped me a lot, that I realized that the article had a problem that interested me more, because of the events that were happening in this , for example: that a study published online through the journal Current Biology revealed that in the period of 25 years, half the size of the Amazon, and twice the size of the state of Alaska, has been exhausted.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but mild curiosity or interest in an article about the Amazon rainforest's decline. Not distress, but concern about the environmental impact of the Amazon's deforestation.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 47,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of two categories: 'not distress' or 'distress bin'. In this context, 'not distress' indicates that the text is neutral or positive, while 'distress bin' suggests the presence of distress or negative sentiment.\nInput: Hello, how have you been lately? I am curious about an article I read recently, said that an Instagram publication of a mother reached almost 400 \"likes\" in her account and more than 800 \"likes\" in the account of the 4th quarter of the Bodies Project. Birth Without Fear also published his photo on Facebook, where he reached more than 6,000 likes., I realized that the article had a problem that interested me more, because of the events that were happening in this one.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but mildly interested or curious",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 48,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. Assign the label 'distress bin' if the text contains disturbing or distressing content related to violence, crimes, or any negative events. Assign the label 'not distress' if the text does not contain such distressful content.\nInput: Hello, I have to tell you something friend, I have some curiosity about an article that I read recently, said that Donald Trump was elected president of the United States. The next day, a man discovered that someone had painted swastikas in an abandoned store in South Philadelphia, I was hoping that this type of information could be in the article\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 49,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input based on the labels ['not distress', 'distress bin']. Mark the output as 'distress bin' if the text reflects distress, such as mentions of violence or war crimes. Otherwise, label it as 'not distress'.\nInput: I have read the article and think that it's a story I have read many times. ISIS claims that the person is part of their army, but there is no evidence that the person was supported by them. It also shows that it's almost impossible to tell whether someone will become a terrorist based on their personality or what religion they are.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 50,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the given labels. If the text expresses distress, assign the label 'distress bin'; otherwise, assign the label 'not distress'. The output should indicate which label the text falls under.\nInput: It's hard to believe that they would go through with this, but they probably want economic growth and that will need extra airport runways. The residents are understandably upset because they will lose their homes, but will likely be compensated. I do think that politicians that said they would vote against expansion and then change their minds, should be voted out.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin, but distress bin maybe slight empathy for the residents impacted but also understanding of the need for economic growth and resignation about the situation.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 51,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on distress level.\nLabels:\n- 'not distress': Text expressing concern or information on challenging situations, but not indicating distress or emotional turmoil.\n- 'distress bin': Text indicating distress, worry, anxiety, or emotional turmoil.\nInput: Some scum bag is at it again stealing naked pictures of people simply because they are celebrities and he can make money from doing it.  It blows my mind the level of shit people will do in order to make a buck.   It seems like people treat celebrities as if they are not people at all.  People that leave negative comments on celebrity pages are taking it to a new level.  People say the shittiest things to each other when they're hiding behind their computer screen.   This particular guy took it to the extreme by stealing their private photos.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distressed but not overly outraged, angry or upset. Worry about the violation of privacy and the lack of respect for people's personal boundaries, but not to the point of emotional distress or outrage.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 52,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the provided text into two categories: 'not distress' or 'distress bin'. Assign the label 'not distress' if the text does not express any form of distress or concern. Assign the label 'distress bin' if the text contains elements that depict distress or emotional turmoil.\nInput: I just read the most terrible article about war and terrorism, I couldn't even imagine the fear these people are living. They are being forced from their homes by threats of death. The conditions in this area are terrible. They're low on most supplies including food. So prices for everything are inflated to prices they can't even afford. I literally cannot imagine at all living in a place like this. There are so many others senseless killings in that area already, I would fear for the life of my family and myself!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern and distress bin humanitarian crisis and distress bin empathy for those affected by the situation]not distress but concern and distress bin empathy for those affected by the situation] not distress but distress bin empathy for those affected by the situation",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 53,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text as either expressing distress or not distress. Assign the label 'distress bin' to texts that convey emotional distress, such as feeling scared, tragic, tough, and mentioning the impact on life and the difficulty of getting over the experience. Assign the label 'not distress' to texts that do not express emotional distress.\nInput: I just read an article about women encouraging other women to get IUD's before Trump took office. They were worried that trump in office will restrict women's access to affordable birth control. They think because the IUD can last for so long that women should get them in soon. I don't think these women need to be out getting IUD's, there are other ways to prevent pregnancy. If they are really concerned, condoms work well.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " no distress bin, but not distress bin either. However, it is not a strong or urgent recommendation, more of a neutral or mild concern. The article is not about distress, but rather a recommendation or advice. It is not distressing, but rather neutral or mildly concerned. No distress bin needed. Not distress bin either. But not a strong or urgent recommendation either. Just neutral or mild concern.",
        "prediction_processed": "not distress",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 54,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the level of distress it conveys. Assign labels ['not distress', 'distress bin'].\nInput: They should really figure out if these earthquakes are due to fracking wastewater, and if so stop the practice. Politicians arenâ€™t concerned about the plight of the ordinary people though. Fracking companies have lobbyists and money, while the victims of the earthquakes have neither. Ultimately nothing will get addressed unless something catastrophic happens.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but concern and urgency about the issue of earthquakes and the potential link to fracking wastewater. The text emphasizes the need for action to be taken to address the issue, but also acknowledges the power imbalance between the affected communities and the powerful fracking companies and politicians. The urgency and frustration are palpable, but not overwhelming distress.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 55,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the emotional state expressed. Assign the label 'not distress' if the text does not convey distress or negative emotion, and assign the label 'distress bin' if the text conveys distress or negative emotion.\nInput: Just because someone happens to be a celebrity doesn't mean that their suffering is any less valid than the average person's. We should learn to recognize that as a society, we must come to understand the universal nature of suffering as applicable to all people. One's status in life should not leave them any more open to suffering than others.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin or distress bin but empathy bin. not distress bin, empathy bin",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 56,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input into one of the two categories 'not distress' or 'distress bin' based on the content. The label 'not distress' should be assigned if the text does not convey strong distress or negative emotions, whereas the label 'distress bin' should be assigned if the text exhibits clear signs of distress or negative emotions.\nInput: He said it would not stop him returning to the field to help save wildlife. Van Niekerk said they were called last weekend to assist a ranger who had caught a poacher near Sabi river. â€œMy colleagues and I, with four Mozambican police officers, were transporting the poacher to the station, which was about 30km away, when he escaped from the vehicle. I chased after the poacher and caught him. I handed him back to the police officer. Suddenly, a mob from the community started moving towards us,â€ said Van Niekerk. The police officers who were with them ran away. â€œWe, the rangers, were the targets.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin, but potentially dangerous situation, not distress bin but exciting or adrenaline-pumping story. Not distress, but potentially dangerous or exciting adventure.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 57,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the level of distress expressed. If the text indicates a sense of calmness, positivity, or lack of worry, assign the label 'not distress'. If the text conveys concern, anxiety, or unease, assign the label 'distress bin'.\nInput: Look at this article. Notice anything missing? Yeah, any sources or any kind of backing for these claims OR any sources for the supposed \"real estate developers\" giving false data.  So, watch how well my feelings beat up this straw man I've set up! You'd think they'd have noticed how long Chicken Little has been going on about this and yet still no fallen sky.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but mild irritation or sarcasm] not distress but not impressed or not convinced by the argument] not distress but mild irritation or sarcasm not distress but not impressed or not convinced by the argument not distress but not impressed or not convinced by the argument not distress but mild irritation or sarcasm not distress but not impressed or not convinced by the argument not distress but not impressed or not convinced by the argument not distress but not impressed or not convinced by the argument not distress but not impressed or not convinced by the argument not distress but not impressed or not convinced by the argument not distress but not",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 58,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the degree of distress expressed. Assign the label 'distress bin' to texts that contain emotional distress or concern, and 'not distress' to texts that do not exhibit emotional distress.\nInput: What an unfortunate situation--and a total shame that regulations on these conditions aren't more thorough. Of course the reputation of the kennel should be considered suspect now. The article says that the business will remain open, but I think it would be best to close up shop. After a news piece like this, I don't think many owners will be bringing their pets to stay.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy for the animals and concern for their welfare, but also some distress or regret about the situation and the potential harm to the kennel's reputation",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 59,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify text inputs as either 'not distress' or 'distress bin' based on the level of distress or emotional intensity conveyed in the text. Labels 'not distress' should be assigned to texts that do not contain distressing or emotionally charged content, while 'distress bin' should be assigned to texts with strong distressing or emotional language.\nInput: It's fascinating to think that these celebrities were fooled so easily by a regular guy. Of course the man's actions are reprehensible, and his jail sentence seems reasonable, but you'd think that celebrities would be more conscious of phishing attacks. Especially since these people gave over their passwords willingly, it's hard to understand the legal precedent for sending someone to jail over this.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but mildly curious or intrigued but also somewhat perplexed or puzzled by the situation",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 60,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into two categories - 'not distress' and 'distress bin'. Assign the label 'not distress' if the text does not indicate distress or negative feelings, and assign the label 'distress bin' if the text conveys distress, negativity, or any form of discomfort.\nInput: I had no idea there is a stunning process when killing chickens, but it makes sense. Unfortunately it seems to not work very well. For all these pieces of convoluted technology being used, no one has been clever enough to think of the solution that we could eat less meat. Certainly it's no secret that animal agriculture is terrible for the planet. Hopefully this will be the next piece in a long line of information pushing us towards vegetarianism.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but environmentally conscious and promoting vegetarianism as a solution to the environmental impact of animal agriculture.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 61,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it expresses distress or not distress. Assign the label 'distress bin' if the text conveys emotional distress, anxiety, or dissatisfaction. Assign the label 'not distress' if the text does not exhibit emotional distress, anxiety, or dissatisfaction.\nInput: It's not pleasant to think of these animals being mistreated, but for all the problems in the world something like this seems rather minor. Of course it would be great to ensure good keeping of animals, but there are more pressing tragedies happening much more often to human beings that we should focus on before addressing these issues of occasional animal mis-handling.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern for animals welfare",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 62,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of the two categories: 'not distress' signifies content with no emotional or distressing elements, while 'distress bin' indicates content with emotional or distressing elements.\nInput: Perception of the physical world does not necessarily result in a universal reaction among receivers (see emotions), but varies depending upon one's tendency to handle the situation, how the situation relates to the receiver's past experiences, and any number of other factors. Feelings are also known as a state of consciousness, such as that resulting from emotions, sentiments or desires.  People buy products in hopes that the product will make them feel a certain way: either happy, excited or beautiful. Or, they find the product useful in some way, even indirectly such as to support a charity or for altruistic economic reasons. Some people buy beauty products in hopes of achieving a state of happiness or a sense of self beauty or as an act or expression of beauty\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " no distress bin, but some cognitive and emotional depth",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 63,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into two categories - 'not distress' and 'distress bin'. Assign the label 'distress bin' to texts that express distress, emotional discomfort, or negativity. Assign the label 'not distress' to texts that do not contain expressions of distress or negative emotions.\nInput: Hello friend,  It's sad that thousands of hectares of tropical forests in Latin America have been changed from their natural habitat to grow bananas. The rise of different types of diseases that focus on banana tress is alarming. I hope we can find a cure for these diseases before it's too late.  I did not realize bananas were a genetic accident. Lucky for us!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 64,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of two categories - \"not distress\" or \"distress bin\". The label \"not distress\" should be assigned when the text expresses disapproval or condemnation of certain actions, such as violence or inappropriate behavior. On the other hand, the \"distress bin\" label should be assigned when the text conveys distress, discomfort, or negative emotions.\nInput: Hello friend,  This article cracks me up. As someone who hates Trump, I think it's hilarious. Realistically, the mother should've just talked to her son about the reasons she dislikes Trump. Trying to convince him that Trump is a immoral person would've been a better use of her time. What makes me mad though, is that people called CPS on her. People always trying to get involved in everybody's business.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but not distress bin either. Humor or irritation, but not distress or not distress bin either.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 65,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the labels ['not distress', 'distress bin']. Determine whether the text describes a distressing event or not by assigning the appropriate label.\nInput: Check out this article.  Remember I was telling you the other day about that man from the bank who approached me in the market?  He was asking about my savings plan and long and short term goals.  He also asked about my mortgage.  I bet he has the same pressures as the bank workers in Pennsylvania.  So shady!  I would never want to work under that kind of pressure.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but rather a slight irritation or nervousness about the situation. Maybe some slight discomfort but not distress per se.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 66,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it expresses distress or not distress. \nLabels: \n- 'not distress': Indicates that the text does not convey a sense of distress or unease.\n- 'distress bin': Implies that the text contains feelings of distress or discomfort.\nInput: I like Lena Heady, and, even though she plays one of the worst mother's on television, I can imagine that she must be a ball of nerves over this custody dispute.  I can;t imagine having to go through this, especially since the custody seemed to be agreed upon.  Her ex husband doesn't seem to be thinking about Wylie's best interest - only his own.  If it were me, I'd fight tooth and nail to kepp my son in the same country as me.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but empathy for Lena Heady's situation. Sympathy for her difficult circumstances.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 67,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into either 'not distress' or 'distress bin' categories. Label 'not distress' for content that does not evoke distress or concern, and label 'distress bin' for content that conveys distressing or alarming sentiments.\nInput: YOu hear about the environmental cost of using coal, but it is very upsetting to read about specific people and how their lives have changed, for the worse, because of coal mining.  Further upsetting is to hear about the animals effected.  Elephants invading villages, being electrocuted, hurting humans, all because their land is being taken for coal.  Sad! People are dying from lack of fresh air and water, and it is wrong.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and distress at the impact of coal mining on people and animals, and the suffering it causes. Distressing images of animals and people affected, and the loss of basic necessities like fresh air and water. Distress and sadness over the harm caused by coal mining.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 68,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input into either 'not distress' or 'distress bin' based on the content of the text. \n- 'not distress': Indicates that the input does not express distress or negative emotions significantly.\n- 'distress bin': Implies the presence of distress, sadness, or negative emotions in the text.\nInput: It must be extremely difficult to find these lone wolf terrorist. I can only begin to understand the type of manpower needed to pursue these people. I think that most of them are mentally ill and hard to catch before they commit the crime. It makes me think of the movie Minority Report and how that type of technology might become available with the advance of A.I..\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but rather empathy and concern for the difficulty of the task of tracking down and apprehending terrorists, and some speculation about the potential use of technology in the future. No distress or negative emotions expressed. Not distress but empathy.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 69,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. Assign the label 'distress bin' to texts that express distress, sorrow, or negative emotions (like sadness, anger, or concern) and the label 'not distress' to texts that do not convey such emotions.\nInput: There are immigrants in this country that are having a hard time assimilation in to the American Culture. The article blames Trump I believe there are most things at work here than just him. It seems the system is working as intended and it was in place before Trump. People need to be able to assimilate as it keeps our country at peace. What do you think we should do about it?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 70,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input into one of two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' to texts that do not convey distress, and 'distress bin' to texts that contain distressing content or emotions.\nInput: You are not going to believe this article I just read about something akin to torture, called conversion therapy. It's something, designed by quacks, that is supposed to convert gay or queer people to heterosexual. Are you kidding me? People are who they are in life and are not to be changed, but embraced and supported. The regimen these poor people had to go through in this so called therapy was barbaric, and would not be used in North Korea as a torture. It's unbelievable what people do in the name of helping.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress, but outrage and sadness at the injustice and harm being done to LGBTQ+ people through conversion therapy] not distress, but outrage and sadness at the injustice and harm being done to LGBTQ+ people through conversion therapy.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 71,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input into either \"not distress\" or \"distress bin\" based on the content. Assign the label \"not distress\" to texts that do not indicate any negative emotional state or concern. Assign the label \"distress bin\" to texts indicating negative emotions, worries, or distressing situations.\nInput: Hi. Just read an article about how Russia is moving some of their military ships near to Britain. What's the deal there? I can really figure out what the Russian government is up to. The article says they are stating the want to keep major waterways safe, but I didn't know there was a problem. Maybe they're creating one.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but curious or concerned about the situation but not distressed or worried. Not distressed bin, but not distressed either. Not distressed bin, but curious or concerned about the situation.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 72,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the labels 'not distress' and 'distress bin'. Assign the label that indicates whether the content expresses distress or not, considering the sentiment and tone of the text.\nInput: Those poor families in the Middle East. Near the city of Yemen. I guess so much fighting over there has led to really unhealthy living conditions. They are having new suspected cases of cholera all the time, and most of those ill are young kids. I can't even imagine such bad living conditions. These kids deserve a better life. Not fear and illness.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin, but also sadness and compassion for the suffering of innocent children and families affected by the conflict in Yemen.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 73,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the sentiment in the text into two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' if the sentiment in the text is positive or neutral without any distressing or saddening emotions. Assign the label 'distress bin' if the sentiment in the text signifies sadness, distress, or any negative emotions.\nInput: Seems like a pretty ordinary occurrence. I'm sure their families are upset but I'm less sure this kind of story deserves space in a newspaper. A couple people got sick and they died. Anyway, it's a mildly sad story but it's not noteworthy or newsworthy. I don't understand why stories like this run in the paper.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but mildly sad or not distressed but not noteworthy enough to be in the paper",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 74,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into the 'not distress' category if it reflects a calm, neutral, or non-distressed emotional state. Classify the text into the 'distress bin' category if it shows signs of distress, emotions like upset, frustration, or negativity.\nInput: The article was about smokers and the prevalence of cancer among cigarette smokers. It indicated that the tobacco lobby results in weak tobacco control and a low effort among politicians to try and stop people from smoking. Quite frankly, I'm not sure why I should care about smokers. The evidence is there for them to see, yet they persist in their bad habits. Government can only do so much and it makes little sense for me to worry about another person's health when they are consciously making the decision to kill themselves.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distressed, but not particularly concerned either. The article presents neutral or even slightly critical views on the situation, with a touch of not-so-sympathetic tone towards smokers. The language used is not emotive or judgmental, but rather neutral or slightly critical. The conclusion that the government can only do so much and it's not your problem to worry about someone else's health is also not overly emotional or empathetic, but rather pragmatic or indifferent. Not distressed, but not particularly engaged either.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 75,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Predict whether the text expresses distress or not distress. In this task, classify the text into either 'distress bin' or 'not distress' based on the emotional tone and content of the text.\nInput: Yuck.  Although I don't think you can say it was particularly disturbing for women because a lot of women voted for the misogynistic ass.  The real problem was reasonable people didn't bother to vote.  I did.  And after the election news I was so depressed, I stayed home and drank wine that day. I didn't have to work.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but not happy either",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 76,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text based on the level of distress it conveys. Assign the label 'not distress' if the text does not express distress or 'distress bin' if the text conveys distress, such as feelings of empathy, concern, or an unsettling situation for an individual.\nInput: Its sad and all but when is there every not trouble in the middle east?  You know my grandmother was Syrian so this maybe should be more personal for me, but its kind of not.  Those people are crazy.  Fell sorry for the civilians though and the united states should really take a lot of refugees from there.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but some concern but not much empathy or empathy towards the situation of the Syrian people. Some not very positive or sympathetic comments towards them, but not quite as harsh as not caring at all. Not distress but also not very compassionate either. Not distress bin, but not quite empathetic or supportive enough either.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 77,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on whether it contains distressing content. Consider labeling the text as 'distress bin' if it includes any distressing information related to the death or suffering of individuals. Otherwise, label it as 'not distress' indicating that the content is non-distressing in nature.\nInput: Hello! I just read this article and would like to share it with you. It is about the oak trees dying along the west coast. I know you are interested and we've talked about this before. It seems to be caused by beetles and they are multiplying faster because of warm temperatures. I wish there was something more we were doing to stop climate change and these warm temps!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but concerned about the environment and the impact of climate change on the oak trees. Not distress but environmental concern.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 78,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it conveys distress or not. Assign the label 'not distress' to texts that do not indicate distress and 'distress bin' to those that indicate distress.\nInput: Passing this article along to you! Remember how we were just discussing this? I guess there is enough doubt now in the death of the Polish former president that died in that plane crash that they now are exhuming the body. Some people suspect that the Russians actually poisoned him and the crash is a cover up! Not everyone's happy about this though as it might seem disrespectful.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but interesting news article about a former president's exhumation and conspiracy theories about his death. Not distress but interesting rumors and speculation. Not distress bin but not distress either. Not distress bin but interesting news article.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 79,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either 'not distress' or 'distress bin' based on the content. 'not distress' refers to text that does not communicate distress or negative emotions, while 'distress bin' refers to text that conveys distress, sadness, or negative emotions.\nInput: I cannot believe that this happened.  I feel so bad for her!  Can you believe she received threats on twitter?  It is cyber bullying for sure.  I cannt imagine this happening to me, how scary!  I am so sad that she had to cancel her account because of crazy people.  Ughhh!  I hope that these bullies are caught and she can go back to her account.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and concern for the person affected, not distress but sadness and worry for their well-be-ing",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 80,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input based on the content's emotional impact. Assign the label 'not distress' if the content does not evoke distress or emotional discomfort. Assign the label 'distress bin' if the content contains distressing or emotionally troubling information.\nInput: It is unreal that so many issues can come out of a natural disaster like this.   YOu would think that we could pull together more and help people!  I cannot imagine what would happen to us if a natural dister happened here, we would never recover.  This is soo scary.  I am thankful for all of the people volunteering time to help!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and concern for those affected by the disaster, but also fear and worry about the potential impact on the community. Distress bin, maybe even a sense of helplessness or urgency.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 81,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the presence of distress. Assign the label 'not distress' if the text expresses positive sentiment or neutral thoughts. Assign the label 'distress bin' if the text indicates distress, worry, or negative emotions.\nInput: Can you believe that these women have to endure this??  I am so thankful that they are standing up for themselves and trying to regain some of their rights.  It is crazy that things like this still go on in this world.  I stand in support of these brave ladies and I hope that no undue harm is caused to them.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but admiration and support for the women' s courage and resilience",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 82,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into either 'not distress' or 'distress bin' based on the level of emotional or psychological distress experienced by the author. 'Not distress' should be assigned when the text contains calm and neutral content, while 'distress bin' should be assigned when the text reflects emotional distress or discomfort.\nInput: Can you believe this happened?  Ughh.  How scary!  I realize that people can be angry with each other, but pushing someone in front of a train??? It is amazing to me that people are so out of control that they can't even handle a verbal dispute with someone.  Its easy, just walk away!  I guess I should stay away from the train platform\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but mild concern or shock",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 83,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into one of the following categories: 'not distress' if the text is positive, uplifting, or neutral in tone, and 'distress bin' if the text contains distressing, negative, or alarming content.\nInput: I had never heard of people shaming women who give birth by C section. This is one of the dumbest things I've ever heard. I'm sure the majority of C sections are medically required to help the mother and the baby, not because women are just so eager to undergo major surgery. Why do people even care if someone gave birth by C section instead of natural birth anyway.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " irritated or angry, but not distressed or upset enough to be in the distress bin] irritated or annoyed, but not distressed or offended enough to be in the rant or irritation bin] irritated or annoyed, but not distressed or upset enough to be in the rant or irritation bin]",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 84,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into one of the following two categories based on the presence of distress-related content:\n1. 'not distress': Refers to text that does not contain worrisome or distressing content.\n2. 'distress bin': Refers to text (even if it seems non-distressing) related to emotional distress or mental health concerns that individuals should be cautious or concerned about.\nInput: Wow, can you believe he survived in the jungle that long on his own?  It is amazing what the human body is capable of hey?  I remember the last time I went a couple days without food and it was so intense.  People think they are ready to survive in the wild but we really have so few skills to get food for ourselves without the right tools.  It's amazing that he was found after all that time.  I wonder how long it will take for him to recover?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but impressive feat of survival",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 85,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' to texts that do not contain expressions of strong negative emotions or distress. Assign the label 'distress bin' to texts showing signs of distress, sadness, or negative emotions.\nInput: The results of the fire could have been worse. I'm just glad nobody died.  Stuff can always be replaced.  Burns are the worst since they're so painful.  Hopefully these people have some family they can stay with until they're able to find a new housing situation. That's great that the firemen were able to get the fire under control so quickly.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but grateful no one was hurt or killed in the fire, relieved the fire was put out quickly, and sympathetic to the people who lost their homes but grateful they are safe",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 86,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories: 'not distress' or 'distress bin'. 'Not distress' refers to text containing little or no emotional distress or concern, while 'distress bin' represents text with significant emotional distress or concern.\nInput: I find it interesting to view the lives of primates in order to try and understand how it relates to our own. The way that the primates dealt with farsightedness seemed very practical to me which shows off their ingenuity and ability to problem solve. It makes me wonder if that's where humans get their own ability to problem solve as well.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but interesting or educational",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 87,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Assign the output label 'not distress' or 'distress bin' based on whether the input text expresses distress or not. \n\n- 'not distress': This label should be assigned when the input text does not convey distress, negative emotions, or urgent concern.\n- 'distress bin': This label should be assigned when the input text expresses distress, negative emotions, or urgent concern. \n\nInput: I think it is a shame that people still lose their lives on trails. Some do not appreciate the dangers of mother nature and try to best her without realizing what they are up against. It is always important to prepare before you go out on a hike. Without understanding what you are doing, a person could easily end up lost or dead.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but rather a message about the importance of safety and preparation when hiking.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 88,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text into one of the following categories: 'not distress' or 'distress bin'. The labels 'not distress' refers to content that does not convey distress or unease, while 'distress bin' signifies content carrying distress or discomfort.\nInput: This type of thing is always largely ignored as it goes on, when people could have known about it but chose not to. Then many years later the truth comes out and some people address it with discomfort, and others still continue to ignore it. The way for real change to come is with accountability. Any crimes that aren't protected by a statue of limitations need to be addressed through prosecution, and they need to look for ways to prosecute instead of looking for ways not to. They should also encourage civil suits, but those are always against the departments and not the individuals. There needs to be reform so that the officers are the ones that are held accountable instead of the taxpayers continually having to make payouts because the police broke the law.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy for victims of abuse of power, but also frustration at the lack of accountability and the need for change. The emotions of outrage, disappointment, and frustration are present, but not distress or despair. It is important to acknowledge the harm that has been done and to demand justice and accountability, but also to recognize the need for systemic change to prevent similar abuses in the future.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 89,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it conveys distress towards Bin Laden or related topics. Assign the label 'not distress' if the text does not express any feelings or interest. Assign the label 'distress bin' if the text indicates negative feelings or concerns related to Bin Laden, sympathizers, or terrorists.\nInput: That idiot deserves a lot worse but hopefully we can erase all symbols of his existence soon. Starting with everything he did as President, but then get rid of all his buildings and everything else with his name on it. Maybe when he pays for his crimes he will have to sell all those buildings off. It would be great to get a full accounting of everything he actually owns so that he can repay everyone he has ever ripped off over his lifetime of scamming people. The name \"Trump\" should forever be associated with crime, grifting, treason, lying, cheating and just generally being a piece of human garbage. Let his stupid kids live with that brand.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but venomous and hateful towards Trump and his family]",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 90,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the level of distress it conveys.\n\nLabels:\n- 'not distress': The text does not convey a distressing or upsetting tone.\n- 'distress bin': The text conveys a distressing or upsetting tone.\nInput: The general rule of thumb is that to be healthy individuals need to get a minimum of eight hours of sleep a night. Some people get more, and some people get along well with less, but everyone needs to get enough sleep or else they cannot function effectively in their everyday activities. In their work, Your Guide to a Healthy Sleep, National Institutes of Health pointed out that sleep is very important to human existence, so important that one-third of a personâ€™s life is spent doing it (1). In Sleep, Sleep Disorders, and Biological Rhythms, Amlaner said, â€œSleep is a required activity, not an optionâ€ (19). During sleep the human body has an opportunity to recuperate from the activities of the day. The recuperation goes beyond tha\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " no distress, just informational text about the importance of sleep. It provides facts and information about the amount of sleep people need and how it is important for human health. There is no distress or concern implied in the text, it is neutral and informative.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 91,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it contains distress-related content or not. Assign the label 'not distress' if the text does not convey distress or negative emotions. Assign the label 'distress bin' if the text expresses distress, sadness, or other negative emotions.\nInput: Hey soul sista. I know this whole Crutcher thing has you shook. I am certain you have read more articles on this matter. Let me say that reading this worries me as well. My wife is worried for her daddy who lives in the area. Please do me a favor and bring this article up in your weekly political meetings. I just want to make sure this gets more movement along the grass root channels you work with. I am sending my best with this article to you.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but worry or concern for others distress or welfrum over the issue of the shooting of a black man by a white police officer and the subsequent protests and responses to the event. Not distress but worry or concern for others distress or welfare. Not distress but not distress but worry or concern for others distress or welfare not distress not distress but not distress but worry or concern for others distress or welfare not distress not distress but not distress not distress not distress but not distress not distress not distress but not distress not distress not distress not distress not distress not distress not distress not distress not",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 92,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into two categories based on the level of distress conveyed - 'not distress' for texts that do not evoke distress and 'distress bin' for texts that express distress or concern.\nInput: I cannot believe this! How can they do this to people? They have less than a week to move out after some of them being there for over 10 years. I am just saddened that political and ideological strife will deny not only teacher from working, but for students to be able to have a quality education. What can we do to help? Let me know if you know what we can rally against.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 93,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of two categories - 'not distress' or 'distress bin'. Texts that invoke emotions of concern, worry, or sadness due to challenging situations or unfortunate events should be labeled as 'distress bin', while texts that do not evoke such emotions are labeled as 'not distress'.\nInput: Remember when I told you I had ringing in my ear sometimes? This article seems to parallel what I was talking about. Can you look into this further? I really trust your viewpoint on this. I am going to ask my doctor about this later on this week. I do not want this to get worse. Maybe you can advise on a good doctor I can see regarding this? I am just really worried about it. Thanks again man!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 94,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it expresses distress or not distress. Assign the label 'distress bin' when the text indicates distress and 'not distress' when it does not.\nInput: Hey I just wanted you know that I read something disturbing this morning in an article. There were bombings and people were killed over fuel. This is alarming and out of control. I'm feeling so many emotions right now. From upset to angry. I don't understand how people can blow other people up over something so trivial and stupid. They were just wanting fuel!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 95,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into two categories - 'not distress' and 'distress bin'. Assign the label 'not distress' if the text does not convey distress, worry, or concern. Assign the label 'distress bin' if the text contains expressions of unease, anxiety, or troubling thoughts.\nInput: Oh my goodness, did you read this article? It was heart-wrenching... I felt so sad while reading it and my heart breaks for the mother of these babies.  There is no way that a parent should ever, ever have to lose a child,muchless two children at the same time. So horrifying and sad!  Something has to be done about all of this. They deserve justice!!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness, but also outrage and advocacy for justice for the bereaved parents. Not distress, but deep sorrow and indignation.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 96,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into either 'not distress' or 'distress bin' categories based on the content. Assign the label 'distress bin' if the text expresses negative emotions, distress, or seriousness towards the topic discussed. Assign the label 'not distress' if the text does not show signs of distress or negative emotions.\nInput: Trump continues to fuck up the nation. Did you read this story of how Trump wants to back out of the Paris Accord? As a nation we are finally trying to seriously address climate change and we are doing that with partners around the world. However, Trump the national embarrassment has seen to it that not only do we not continue trying to make the planet better, but we also betray our allies.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 97,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it expresses distress or not. Assign the label 'not distress' if the text does not convey distress or 'distress bin' if the text indicates feelings of distress.\nInput: you can never really trust a person.Someone can end up dead and those who are left in the wake are the ones that suffer.Really makes you think just how short of a life we have in comparrison.But having no sex can do something to a person.It is one of those things that we have a bond between a person and if something in a relationship is not working it can drive a person to do something they would normally not do.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress but rather a cautionary tale or a reminder of the fragility of life and the importance of relationships, including intimate relationships. It also touches on the idea of the intensity of human emotions and the potential for negative consequences when things are not working in a relationship. Not distress but rather a cautionary tale. not distress but rather a reminder of the fragility of life and the importance of relationships. not distress but rather a cautionary tale or a reminder of the fragility of life and the importance of relationships, including intimate relationships.not distress but rather a cautionary tale or a reminder of the fragility of life and the importance of relationships, including int",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 98,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the presence of distressing content. Assign the label 'distress bin' if the text contains distressing information related to war, violence, or suffering of innocent civilians, otherwise assign the label 'not distress'.\nInput: That's a really strange and messed up situation. It's really sad for the children involved and it's very troubling that any country could plan out such an awful attack. I hope that things change in those areas of the world and more security is put in place so these types of attacks can be detected and negated.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 99,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on distress level. Assign the label 'not distress' if the text contains information that is neutral or not alarming. Assign the label 'distress bin' if the text contains information that could evoke feelings of discomfort or distress in the reader.\nInput: it's dissapointing that in this day and age that homosexuality is still illegal in different countries. I would think that it would be past that and that people would just get over it. It took forever for America to recognize gay marriage so I guess it's not surprising that Uganda hasn't yet. But I still think that it's a breach of human rights and it's moraly wrong\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but dissapointment and moral outrage at the fact that homosexuality is still illegal in some countries, and that it took a long time for the US to legalize gay marriage. Disturbed by the fact that this is still an issue in some parts of the world, but not yet universal human right.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 100,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Train a text classifier to predict distress or non-distress based on input texts. The labels are as follows:\n- 'not distress': Represents text content that does not convey distress or a state of emergency.\n- 'distress bin': Indicates text content that conveys distress, emergency situation, or critical stress.\nInput: This sounds like such a freak thing.  It must be so hard for the family because there are no answers and they need answers.  I'm not sure this is something that is easy to figure out.  It sounds like a severe case of pneumonia, but from what, how and why.  And the fluid on the brain of the one sister is so strange.  I would think they would know more after the autopsies, and I don't understand why that is taking so long.  I'm thinking that the family wants to bring the bodies back to the States and that could be holding up the autopsies.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Sympathetic but worried for the family's distress and uncertainty, but also frustrated by the delay in autopsy results. The not distress bin is used to show empathy and support, but also to convey the distress of the situation.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 101,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of two categories: 'not distress' or 'distress bin'. Texts expressing strong negative emotions, concerns, or distress related to poaching of elephants and rhinos should be labeled as 'distress bin', while texts that do not convey distress should be labeled as 'not distress'. In this case, the output is 'distress bin' as the text expresses upset feelings about the poaching of elephants and rhinos.\nInput: Working out is important, but you may want to check the ingredients of the supplements you take. This article talks about a number of ingredients that can cause dangerous side effects and are also very common in work out supplements. It's scary to think about what we are putting in our body. From now on, I am probably going to cut back and go more natural.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 102,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into one of the two categories - 'not distress' or 'distress bin' based on the emotional content. If the text expresses genuine distress, assign the label 'distress bin'.\nInput: I just read this article about a scandal involving a person trying to rent a place from someone else, but then it turned out that this person was using it for personal reasons because the place the other person was renting wasn't own bu the person they thought. It would be interesting if the author of the article didn't try so hard to sound like a kid using slang.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " no distress bin, but maybe a mild irritation or criticism of the author's writing style, but no distress bin needed.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 103,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into two categories - 'not distress' and 'distress bin'. Assign the label 'distress bin' if the text exhibits distressing or emotionally troubling content.\nInput: I just read this really long article about a white man that actually got sentenced after shooting a black teenager dead. I can't help but feel incredibly satisfied after reading this. It happens way too much in this country where white people are able to get away with hurting black people. This time, it finally feels like some justice has been done.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin, satisfaction or schadenfreude or vindication, but not quite justice or revenge, but a sense of satisfaction or vindication, but not quite justice, but a little bit of revenge or schadenfreude, but distress bin, distress bin, distress bin, distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 104,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text as distress or not distress based on whether the content evokes negative emotions, discomfort, or uneasiness.  \nLabels: \n- 'not distress': Refers to text that does not provoke distressing emotions or discomfort.\n- 'distress bin': Refers to text that evokes negative emotions, discomfort, or uneasiness.\nInput: I just can't imagine that this poor 4 year old was blinded the way she was. But then I wonder if it is truly an act of justice to carry out the same punishment on the perpetrator. It seems so human to want revenge, but it also feel so useless. In a way it seems to make \"us\" as \"bad\" as him. It just makes me sad.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 105,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the provided text into two categories - 'not distress' and 'distress bin'. Assign the label 'not distress' if the text indicates a negative opinion or criticism without expressing extreme distress or emotional disturbance, and assign the label 'distress bin' if the text conveys distress, emotional upheaval, or a negative sentiment that indicates strong emotional reactions.\nInput: This is such a sad story. I feel so much for the mother trying to get away. Sometimes it seems like things won't be so bad. Sometimes it seems like tomorrow is another chance, but it seems to me that you can't give people the opportunity to destroy because they will. I would always encourage a one strike policy for my friends. That reminds me, how was your friend after her husband threatened to shoot her - are they still together?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but sympathy and concern for the mother's situation and empathy for her plight, with a hint of advice or opinion about how to handle the situation",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 106,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' or 'distress bin'. 'Not distress' refers to texts that do not express emotional distress and have a neutral or informative tone. 'Distress bin' includes texts that express emotional distress, concern, sadness, or any negative emotion.\nInput: Wow - this is so so horrible! I can't even begin to understand why Syria would attack its own citizens, and why would Russia support them in doing so? This is a sick regime and I am glad that America and its allies are interfering. The fact that they are denying doing it is truly messed up. I hope these poor children who survived are able to get the healthcare they so desperately deserved. Could you guys imagine if this was happening here??\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and outrage at the situation in Syria, with sadness and condemnation of the actions of the Syrian regime and Russia, and support for the intervention of the US and its allies. Sympathy for the innocent victims of the conflict.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 107,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Determine the level of distress reflected in the input text. Assign the label 'not distress' if the text shows a lack of concern or interest in the news content related to Mariah Carey and related events. Assign the label 'distress bin' if the text reflects emotional distress or empathy towards the ex-boyfriend or husband mentioned.\nInput: I saw this news item about a shooting in North Philly. Is this near where you live? Damn, I am so sick of gun violence. Will it ever end? Every day, it seems to be something new. Here in Detroit, we see it all the time and I know you're in a similar situation in Philadelphia. The article doesn't give any details about the victims or anything like that. It almost dehumanizes people, don't you think? I mean, these victims were somebody's relatives. Hopefully more details will come out in future articles. The news media cares more about being the first to report a story instead of sticking around to find out the details. I know I am rambling here. But all this gun violence is too much.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but distressed about gun violence",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 108,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text as either expressing distress (emotional pain or suffering) or not expressing distress. Labels are 'not distress' and 'distress bin'.\nInput: I don't understand why there is so much hate. It's like every one lives in their own little bubble seeing everything foreign to them as a threat. They take up selfish ideology because they don't like something, instead of just disassociating with it. This greatly saddens me, for I have seen the world in all it's wonder. Where the majority of people just want to live in peace, without boundaries. Yet this idea of cultural heritage has become disastrous further dividing people. If only more people could set aside their petty ideals, and just accept each other as other humans. Instead we classify and further separate ourselves due to every difference. I would prefer to just die, than put up with such cruel disgusting people. I am disgusted with my country of Americans. We deserve to burn....\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distressed and upset by the prevalence of hate and division in the world, and frustrated by the inability of people to understand and accept each other's differences] distressed and upset, saddened by the state of the world and the division and hatred that exists between people. The use of strong language such as \"disgusted\" and \"cruel\" indicates a deep emotional distress and sadness.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 109,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Assign the label 'not distress' or 'distress bin' based on whether the input text expresses a feeling of being not distressed or falls into a category of general distress, respectively. \n\n- 'not distress': Represents content that conveys a lack of anxiety or worry.\n- 'distress bin': Represents content that may evoke emotions related to stress, concern, or unease.\nInput: I feel that we are prioritizing efforts of saving the planet in the wrong way. We want to ban this or that, and that's great and all. However, we are missing the bigger picture. We need to focus on building a world that co exists with nature, instead of just saving little bits of it here and there. While some strive to save this or that, there are a million other things destroying it further. We need to end the destruction of our global ecosystem, and not pick and choose species to save. Other wise there will be nothing left, and those efforts would have been in vein.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress, but concerned about the environment",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 110,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. If the text expresses distress, anxiety, or negativity towards the mentioned subject matter, label it as 'distress bin'. Otherwise, label it as 'not distress'.\nInput: If people are concerned about others to where they feel fear. They need to leave the situation entirely. No working things out, no seeing what happens. If you feel threatened, LEAVE! The problem is most people think they can't just drop everything. But it's mostly because they either don't know how, or don't want to live any other lesser lifestyle than they are accustomed to. Kids run away all the time from home with no skills, or means to get by. Many of them end up making it out ok. Some don't, but it's usually due to making the wrong choices. Taking the easy way out. We are free to make our own choices, and live the life we can live. So why would any one ever put up with feeling threatened, when they can just leave, and disappear. Even if you have no where to go, you can always die.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin, but also some tough love advice",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 111,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the emotions expressed into the \"not distress\" or \"distress bin\" categories. In this task, texts that communicate feelings of being upset, disturbed, or troubled should be labeled as \"distress bin,\" while texts that do not convey distress or concern should be labeled as \"not distress\".\nInput: So I just read an article where 2 friends went diving to a place they shouldnt have and ended up dying. While they were using brand new equipment, I feel like idiots who take stupid risks and go to places where no humans should be, kind of deserve what ends up happening to them. If you dont sky dive, you never have to worry about going splat when your chute doesnt open\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but rather, somewhat distressed or no distress bin, but also a bit critical or judgmental of others' actions, but not necessarily distressed or worried about their fate] not distress, but a bit critical or judgmental of others' actions, no distress bin but also some distress or concern but not enough to be in the distress bin. not distress but rather, somewhat distressed or no distress bin, but also a bit critical or judgmental of others' actions, no distress bin but also some distress or concern but not enough to be in the distress bin. not distress bin not distress bin but somewhat distressed or no distress bin,",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 112,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text as either 'not distress' or 'distress bin' based on the emotional content expressed. Assign the label 'distress bin' to texts with a sorrowful or troubled sentiment, and the label 'not distress' to those lacking such emotions.\nInput: It would appear to me, in my opinion, the liberal, nonsensical, mainstream media is at it again. Let's use fear-mongering and misinformation to stir up a demographic in our all out effort against Donald Trump. I feel for those who don't read the actual proposals and/or legislation but instead decide to believe every word uttered by the talking head on TV.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin or critical but not distressed emotion",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 113,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the content and assign the appropriate label.  \nLabels: \n- 'not distress': Indicates text content that does not express distress or negative emotions.\n- 'distress bin': Indicates text content that demonstrates distress, negative emotions, or emotional turmoil.\nInput: Guys, please read this. This issue needs to be seen by more of us and acknowledged as something that happens more than we realize. Is this something we can change or work on as a community? Please help me think of ways we can work on making this a nonissue in the future for the next generation. This is our kids and grandkids future we are thinking of.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and urgency, but not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 114,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the given labels into \"not distress\" or \"distress bin\". The label \"not distress\" should be assigned to texts that do not evoke distress or sadness, such as informational or neutral content. On the other hand, the \"distress bin\" label should be used for texts that contain distressing or upsetting content that may evoke strong emotions in the reader.\nInput: This shows how the current political environment is effecting people, especially younger people, emotionally. The stress and fear that is being shown from the younger generation is mostly to blame on social media. We used to be able to discuss political issues in person, calmly. Now, if you try to mention your opinion on social media, you run the risk of being attacked or insulted, simply adding to the fear of the current political situations.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress, but concerned about the impact of social media on young people's mental health and political discourse",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 115,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the level of distress indicated in the content. Assign the label 'not distress' to text containing no distressing language, sentiments, or indications of emotional discomfort. Assign the label 'distress bin' to text containing distressing content, such as expressions of discomfort, sadness, worry, or anxiety.\nInput: Hey everyone, please share this! She appears to be in her late 60s or early 70s, 6'0\", 175lbs, with gray hair. This could easily be someone's grandmother or mom, a family could be worried sick about her. Her outfit sounds like she may of been in some sort of retirement home or something similar. I know if this was my grandmother I could want to know so I could help her get home, so please share this within the area so we can maybe get her back to her home and family.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-being)not distress, but concern for a missing person's well-",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 116,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it expresses distress or not distress. Assign the label 'distress bin' if the text conveys a sense of worry, fear, or concern.\nInput: The Somali peope are suffering greatly. I feel so bad for what they have had to go through over the past while. Donald Trump doesn't have enough mercy or understanding for what they are going through. The United States may offer some help, but not nearly enough. They will be in poverty likely their entire lives, and it is just not fair. There must be a way to test to see if they are dangerous, and if not they should be welcomed into our country.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 117,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the level of distress it conveys. Assign the label 'not distress' if the text does not express distress or emotional upset, and assign the label 'distress bin' if the text conveys distress, disappointment, or negative emotions.\nInput: Kisii is a real tragedy. Many people are dead, and more people are severely injured. The drilling is likely what caused it, and the developer should be held responsible. He has caused much pain and suffering. Kenyans deserve better, and since he didn't listen to NCA warnings, he should pay for what he did. The other buildings in the area should be thoroughly tested to see if anything can be done to prevent this.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 118,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. For the provided text, assign a label based on whether the content expresses distress or not.\nInput: Rhinos are going extinct, and it s a real shame since they do nothing to harm human life. They are a majestic creature with much to offer. However, they are being killed because of poachers and their horn. The black rhino is almost extinct. Only about five thousand still exist in the world today, and this is a real shame.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness for the plight of the rhinos, but not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 119,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of the following categories - 'not distress' or 'distress bin'.\n\nDescription of Labels:\n- 'not distress': Indicates that the text does not convey distress or emotional difficulty.\n- 'distress bin': Indicates that the text conveys distress, emotional weight, or difficulty.\nInput: It's upsetting that species are dying out, sometimes before we even know they exist. I wonder if there are ways we can use science to bring them back, if they even survive if we do. We need to take better care of the environment. It's worrying that as these species die out, someday ours might as well.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but worried about the environment and the loss of species",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 120,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress expressed. Assign the label 'not distress' if the text does not convey distress or harm towards animals. Assign the label 'distress bin' if the text expresses emotional distress, empathy, or concern for animals being hurt or mistreated.\nInput: Ugh, another example of crappy cops. They think they can get anyway with anything. I've started to pull out my phone camera whenever I see the cops talking to someone, especially if they are a minority. Police brutality is such a problem in our country and it's just so deeply ingrained in the system, I'm not sure what can be done. We need some kind of overhaul of the criminal justice system.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but frustration and concern about social justice issues, no distress but righteous indignation and desire for change",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 121,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on distress level. Label as 'not distress' if the text does not indicate distress or 'distress bin' if the text contains distress-related information, like wildfires or hazardous situations leading to distress.\nInput: I just cannot even imagine something like that happening. What makes someone do such a horrible thing? And especially when there were children on board? Such a senseless act. How scared those individuals and the victim must have been when that was happening. It is a good thing that that guy was there to help the passengers get off the bus. A tragic event would have been even more tragic had he not been there to save those people. I feel bad because those individuals (including the guy who saved the passengers) are all now scarred for life and their lives will never be the same. Their lives have been turned upside down because of someone else's senseless act and are forever traumatized by it. I hope those victims get the support they need and I hope that the driver's family receives support\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness for the victims and their families, but also sadness and distress at the senselessness of the act and the impact it had on innocent people's lives. Sympathy and compassion for the victims and their families, and hope that they receive the support they need. Not distress, but distress and empathy.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 122,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into two categories - 'not distress' and 'distress bin'. Assign the label 'not distress' if the text describes a situation that is not distressing or alarming, such as explaining an unethical behavior without causing personal distress. Assign the label 'distress bin' if the text contains distressing content that may evoke negative emotions, anxiety, or fear when read.\nInput: This makes me feel nothing. I don't care about this. I don't see why I have to care about this. Bad things like this happen all the time and they have no affect on me. I have too many problems of my own to have to worry about more things like this. Thinking about this kind of stuff just adds to my stress.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 123,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into two categories - 'not distress' and 'distress bin'. Assign the label 'not distress' if the text indicates that the situation is under control or there is no cause for concern. Assign the label 'distress bin' if the text shows signs of distress, unease, or emotional turmoil.\nInput: The only solution for the \"wage gap\" is the total abolishment of capitalism and all governments. There will be no more wage gap when there is no money! By instituting Anarcho-Communism, all people can be given what they need without a worry of who is getting more or less. Capitalism is evil and must be destroyed!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but highly emotional and impassioned rhetoric, with a revolutionary or utopian vision for a future society] not distress but highly emotional and impassioned rhetoric, with a revolutionary or utopian vision for a future society. Not distress but a call to action and a vision for change.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 124,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the presence of distressing content. Assign the label 'not distress' if the text does not contain distressing elements and 'distress bin' if the text contains distressing information related to gun deaths and violence against children.\nInput: This was a somewhat interesting article about the frequency of eye injuries in sports for children.  They really could have used more data in the article but interesting all the same.  The only real gripe I had was somehow playing with airsoft guns around the house are counted as sports related injuries so the data doesn't seem that reliable.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 125,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text inputs into either 'not distress' or 'distress bin' labels based on the emotional tone or sentiment expressed in the text. The 'not distress' label should be assigned for texts that do not convey distress, anxiety, or alarming emotions. The 'distress bin' label should be assigned for texts that evoke distress, anxiety, or alarming emotions.\nInput: It's such a shame the man had to shoot the dog.  Labradors in general are decent dogs and not know to attack people for no reason.  He could have shot into the ground or into the air to scare the dog off.  I feel bad for the lady that lost her dog but this is why you keep your dogs on leashes.  If she hadn't let the dog off the leash this probably would not have happened.  It's a terrible and unfortunate situation all around and I hope I never find myself with the same problem.  I'm gonna go play with my dog now and be grateful.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but sadness and concern for the lady who lost her dog and empathy for the situation. No distress but sympathy for the lady's loss and the idea that a tragedy could have been avoided if the dog had been kept on a leash.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 126,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text as either 'not distress' or 'distress bin' based on the content. Assign the label 'not distress' if the text does not express distress or negative emotions. Assign the label 'distress bin' if the text contains distressing or negative sentiments.\nInput: It is very difficult for me to imagine how any person could leave a baby in a shoe box.  I just don't understand how you could even leave a baby alone.  Thank God the baby was in good health, at least whoever left the poor thing seems to have taken good care of it other than leaving it in a shoe box.  Maybe in the end this will turn out to be a good thing for this baby, one can only hope.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but worried about the baby's safety and lucky it was found safely",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 127,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into two categories: 'not distress' and 'distress bin'. The 'distress bin' label should be assigned to texts expressing sadness, concern, or emotional distress relating to situations of harm or tragedy, while the 'not distress' label should be assigned to texts that do not convey such emotions.\nInput: Those poor officers.  Like in any group of people, there are good and bad ones.  In this society the tendency to demonize everyone for the actions of a few sets a very dangerous precedent and things like this can happen.  Every person should be judged on their own merits.  Saying all cops are bad because of what a few have done is so insane and the public outrage leads to things like this.  I don't know for sure what this person's motivations were but there have been enough instances that some don't see law enforcement as people anymore and it makes their job so much more dangerous and we need good cops to do their jobs to keep us safe.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin but also a call for empathy and understanding for the officers involved in the situation and a plea for fairness and not generalizing all law enforcement based on the actions of a few individuals. The distress bin label is a sympathy for the officers who may be unfairly judged and the danger their job poses due to public outrage. The distress bin label is also a call for empathy and understanding for the officers involved in the situation and a plea for fairness and not generalizing all law enforcement based on the actions of a few individuals.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 128,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it reflects distress or not. Assign the label 'distress bin' to texts that discuss or imply distress, and 'not distress' to texts that do not convey distress or negative emotions.\nInput: Remembering those who have lost their lives due to violence is so important. Do you remember what happened in Paris in 2015? I am so grateful that the people there set aside a special time to remember all the victims and their families. Such a senseless loss. People just wanting to enjoy some entertainment were met with a horrific experience and families were forced to wait in pain to hear news of the outcome. I am sure they will never forget that day.  I do hope each day gets easier for them and that they remember the good memories of their loved ones.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sorrow for the victims of violence in Paris in 2015",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 129,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text based on the distress level into two categories: 'not distress' for text that does not indicate distress or negative emotions, and 'distress bin' for text expressing distress, anguish, or negative feelings.\nInput: I just read a very upsetting article about a recent incident involving U.S. troops in Jordan and I wanted to share it with you. There were three U.S. military trainers killed in gunfire by security units at Jordan base, fatally shot by security forces Friday when their vehicle failed to stop at the gate of a military base. I have no idea why the driver did not stop at the gate, which is certainly protocol. They have had serious problems in Jordan recently due to hundreds of thousands of Syrian refugees crossing their border. Jordan is and has been a significant U.S. ally in the war against ISIS and I can only hope that this incident is isolated and not part of a bigger problem. God bless the families of the deceased soldiers!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Sympathy and concern for the families of the deceased soldiers, but also worry and sadness about the incident and its potential implications for the relationship between the U.S. and Jordan. Sympathy and condolences for the families, but also concern for the security and safety of the troops and the potential impact of the incident on the relationship between the two countries. Not distress but sadness and worry.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 130,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into one of the two categories:\n1. 'not distress': Text that does not contain distressing or disturbing content.\n2. 'distress bin': Text that contains distressing or disturbing content, such as violent, graphic, or alarming information.\nInput: I just read an article about tour boat that capsized because of the boat operator. It was horrific reading the statements of the survivors. It brought chill to my bone when they wrote many situations that could of ended their lives. Just imagining what I would of done in that situation makes me feel troubled because I cant really swim in open water. All the survivors are now suing the company for injuries, recklessness, neglect, and trauma. Pretty crazy how one event can change the outcome of life or death.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and shock at the tragic accident, fear for the survivors' well-being, and concern for their safety, but also vulnerability and worry about one's own safety in similar situations",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 131,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the level of distress expressed in the text.  \nLabels:  \n- 'not distress': Indicates the absence of distress or emotional concerns in the text.  \n- 'distress bin': Signifies the presence of distress, emotional upset, or concern in the text.\nInput: Another article I read showing a death of African American driver by a police. I really upset me reading this article. That unnecessary force was used to handle the situation. Its crazy that the first thing on the police mind is to shoot to kill. I feel uneasy every time seeing and reading about situation like this where a situation could of been handled in a different way. Understandable that they work in a high intense environment but that why they train and follow protocol.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 132,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into either \"not distress\" or \"distress bin\" based on the content. Assign the label \"not distress\" to texts that discuss topics of interest or positive content, like animal rescue operations, in this case. Assign the label \"distress bin\" to texts that contain distressing information, such as harrowing conditions or events like the launching of missiles during evacuations.\nInput: Have you ever heard of sudden oak death ? Over 66 million trees have just vanished since 2010 . bacteria is  spread through the water . This is a scary thought where are we going to be at in the next 5 years? I think that we need to take note and start worrying about our planet this is not a good sign at all .\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but worried about the environment",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 133,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on distress levels into 'not distress' or 'distress bin'. 'Not distress' indicates the absence of distressing content in the text, while 'distress bin' signifies the presence of distressing elements such as fear, sadness, or emotional discomfort.\nInput: I really hate ISIS. They are the scum of the earth. I just learned that they killed over 100 Iraqi police officers in Mosul. This is the kind of thing that happens when we pull our troops out of Iraq. Yeah we should not have been there in the first place but we made that mistake and we now have to take responsibilty for it. I feel so bad for all the Iraqi people who just want to live their lives in peace.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but anger and sadness] not distress but anger and compassion towards the victims of ISIS attacks and sympathy for the Iraqi people affected by the conflict.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 134,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on emotional distress level into two categories - 'not distress' for text expressing no distress or neutral sentiment, and 'distress bin' for text representing emotional distress, anxiety, or discomfort.\nInput: I am shocked and saddened by this earthquake. What a sad and terrible tragedy. I feel so sorry for all the victims and those affected by this event. I can't even imagine how devastating this must be for them. What an incredible catastrophe. My thoughts and prayers and best wishes go out for all the many people affected by this tragic catastrophe. I hope that everyone stays safe for the foreseeable future. I am still in shock.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 135,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into either 'not distress' or 'distress bin' categories. 'not distress' label is for texts that do not convey distress or worry, while 'distress bin' label is for texts that express distress or concern regarding a particular issue or situation.\nInput: I feel really concerned that they have no idea who committed this crime. I wonder if there's more to this story. I wonder what the conditions were that led up to this event. I hope the victims will make a full recovery and that they catch this horrible person! My thoughts are with them and their families!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Concerned for the victims and their families, hope for a full recovery, and worried about the lack of information and the possibility of the perpetrator still being at large. Sympathy and concern for the victims and their loved ones.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 136,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on distress level, assigning it to one of two categories - 'not distress' or 'distress bin'. In this context, 'not distress' would indicate a lack of emotional distress or disturbance in the content, while 'distress bin' would indicate that the content contains elements or information that evoke distress.\nInput: After reading this article it seem like a nightmare is becoming a reality. Today drug user, especially opiod user, are taking there drugs in front of their children. It seems like the drug user are tired of taking their drugs and having people around them disagree with their habits. Its really a shame that parent are doing these drugs in front of their kids.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress but not overwhelming distress] worry and sadness about the impact of drug abuse on families, especially children.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 137,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the emotional distress content into two categories - 'not distress' and 'distress bin'. 'not distress' label indicates that the text does not contain any distressing elements, while 'distress bin' label indicates that the text includes distressing content.\nInput: Colonialism is a ugly part of American history, but it's one that we shouldn't forget. We can't undo the damage that we've done, but we can teach future generations our mistakes, and hope that they do not repeat them. A formal apology is the very least the Canadian government can do, and it is admirable.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin, but not distress bin either. The text is not distressing, but it is emotionally impactful, as it acknowledges a painful and uncomfortable aspect of history. The tone is reflective and respectful, and there is a sense of sadness or regret in the acknowledgement of past wrongs.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 138,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on emotional distress, assigning one of the labels - 'not distress' or 'distress bin'. In this case, the text expresses concern and fear about the zika virus and its impact on children, indicating emotional distress, so the output label would be 'not distress'.\nInput: It's unfortunate what happened. If I was a politican I'd say my heart and prayers go out to the victims affected, but honestly? It's hard to feel much sympathy for people so far away. I find the governments efforts to house and protect the affected civillians admirable. We have federal agencies devoted to disaster relief in the US, but we only go so far in helping people.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 139,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into either 'not distress' or 'distress bin' categories based on the content. Assign the label 'not distress' if the text does not contain any distressing or negative sentiment. Assign the label 'distress bin' if the text conveys distress, negativity, or any form of discomfort.\nInput: How can Canada think that was the right course of action? Of course we are no better with how we treated the Native Americans. These poor kids are ripped from their homes and subjected to such horrors because of who they are. It is sickening. It is as if we have no respect for the past. Who cares if they didn't speak the language or assimilate into \"normal culture\". Is that any reason to destroy their lives? No apology could ever fix what was done. So many children died, just because they were born into the \"wrong\" culture. This mentality, unfortunately, isn't isolated or gone from planet. We are destroying the identity of people who for the most part probably just wanted to live and die without interfering with the \"new\" culture. Is it so wrong to be different?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but distressing and saddened by the injustice and suffering of the Native American children taken from their homes and subjected to abuse and trauma. The article highlights the historical injustices and the ongoing impact of colonization and forced assimilation on Indigenous peoples in Canada and around the world. It is a powerful and important reminder of the need for reconciliation and healing, and the importance of respecting and valuing the diversity of cultures and identities.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 140,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the provided text into one of two categories: 'not distress' or 'distress bin'. Assign the label 'not distress' if the text is conveying a positive or neutral message, and assign the label 'distress bin' if the text is related to distress, worry, or negative emotions.\nInput: The spread of cholera is very widespread in Haiti. It is costing tons of lives, and money food and doctors are very much needed. Its hard to control like any other high spreading disease. Doctors need resources so much that they cant keep up with ever growing number of patients. They need food, medical supplies, and other miscellaneous equipment that would help them improve their job and combating the outbreak.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but distress bin - urgent need for aid and resources to address the crisis in Haiti",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 141,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either 'not distress' or 'distress bin' based on the sentiment expressed in the text. \n- 'not distress': Denotes a lack of distress or calm sentiment.\n- 'distress bin': Indicates a distressed or emotionally charged sentiment.\nInput: People and government and climate groups are scared President Trumps cabinet would push climate control policies back. He might put the states out of the Paris Treaty, and build more Coal factories that might emit more toxic fumes into the air and expand global warming. And in regards to other countries they might agree with it to as well, putting our earths climate at a dangerous risk. This might other protocols as well such as the Kyoto protocol\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern about the potential impact of President Trump's actions on the environment and climate change. The text expresses worry about the possible rollback of climate control policies and the potential harm to the environment if the Paris Treaty is abandoned or if more coal factories are built. It is a not distress but a concern for the future of the planet.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 142,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into categories of distress and non-distress. The label 'not distress' is assigned to text expressing negative feelings towards timeshare companies and their practices without mentioning personal emotional distress. The label 'distress bin' is for text that includes personal emotional distress when discussing timeshares or related issues.\nInput: Hey, Josh have you seen this? World currencies are going to be taking a hit, I just wanted to let you know. The complete misunderstanding of how to run something as simple as a bank multiplied by thousands around the country of India is bringing that country to its knees. We see this happen all the time where markets are controlled by the government and something stagnates then we add more controls and now we have a depression.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but somewhat negative about the state of the global economy and the potential consequences of government intervention in financial markets, but not distressed or alarmed.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 143,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it contains distressing content or not. Assign the label \"not distress\" if the text does not contain distressing material, and assign the label \"distress bin\" if the text does contain distressing material.\nInput: Wow. That is really sad!!!!!!!!!!!!!! I wonder why his friend would kill him. Must not have been friends after all, huh?????? I wonder how long the body had been there before he was found. Money was probably the motive since it usually is. He probably got over on him somehow and dude got his revenge. Oh well.......\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but rather sad and intriguedrumor or speculation about a murder but not distressing enough to be distressing not distress but rather sadrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a murder not distressing enough to be distressingrumor or speculation about a",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 144,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either 'not distress' or 'distress bin' based on the content. Assign the label 'not distress' if the text does not convey a sense of distress, whereas assign the label 'distress bin' if the text contains elements indicative of distress, hardship, or suffering.\nInput: Just read a short article about the Kim Kardashian robbery.  Pretty scary for her, and the robbers kept demanding money.  There were language/communication issues between her and the robbers, she thought they wanted her jewelry, and they wanted her money.  I hope that she gets better security in place so that this never happens again.  The article mentioned her providing information about her expensive diamond ring on Facebook - I think there's a lesson to be learned about that.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concerned for her safety and security",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 145,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the provided text into 'not distress' or 'distress bin' categories based on the sentiment expressed. The 'not distress' category includes texts that are not emotionally distressing or upsetting, while the 'distress bin' category includes texts that express distress, sadness, anger or any other negative emotions.\nInput: I feel so sorry for these people trying to flee their current situation.  These crossings need to be safer for these people.  All of these people drown and for what?  A chance at freedom, a chance to get away from what they fear, and I feel like these people need to be helped and find a way to get them across safely.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and distress for the people in danger of drowning while trying to escape their situation, urging for safer crossings and help for them. Sympathy and compassion for their plight.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 146,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on whether it expresses distress or not distress. Assign the label 'distress bin' if the text conveys a sense of distress, or 'not distress' if the text does not indicate distress.\nInput: I just read a troubling little snippet about a family who lost their home in Washington D.C. They haven't yet identified the cause of the blaze, but a family of five ha not only been displaced, but they also lost two cats which I'm sure were very dear to them. I'm glad to hear that the Red Cross has stepped in to lend aid to this needy family.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and concern for the family's well-being, but no distress bin needed yet as the family is receiving aid from the Red Cross.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 147,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the given labels into 'not distress' or 'distress bin'. The label 'not distress' should be assigned to texts that do not convey a sense of emotional distress or unease, while 'distress bin' should be assigned to texts that contain distressing or troubling content.\nInput: I know we have been talking about climate change, my friend. I read a news article that continues to build upon the foundational knowledge that we have speculated upon. As it turns out, a mere one degree Celsius change can have major impacts on the ecosystem. It affects genes and ranges in species. More than eighty percent of ecosystems are being put under stress. It makes me sad because we don't know the long-standing implications in the largest perspective. Every single day we can make choices to help negate the bad choices our species makes towards our environment.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concerned about the impact of climate change on ecosystems and the potential long-term consequences for the environment.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 148,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the emotional tone into two categories - \"not distress\" or \"distress bin\".\n- \"not distress\": Text that does not express distress or emotional pain.\n- \"distress bin\": Text that conveys distress, emotional pain, or indicates a disturbing or troubling content.\nInput: It is so unfortunate that people are being attacked because of their religion. A lot of Christians in Mosul were ordered to convert away from their beliefs or suffer heavy consequences. This is not a choice most people want to make, let alone be forced to flee their homes. Churches, homes, and streets were not safe. Many people have considered fleeing over returning. However, the human spirit is strong. We all face adversity. Some are brave enough to face the terror and harassment they experienced to rebuild their lives.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and concern for the people affected by the persecution, but not distress or despair. Sadness and worry for their plight, but also inspiration from their resilience and strength.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 149,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the level of distress expressed. Assign the label 'not distress' if the text does not convey distressing emotions or situations, or assign the label 'distress bin' if the text indicates distress, worry, or emotional unease.\nInput: I just read about the arrest of the women from that National Geographic magazine. You know, the one with the striking green eyes. She's in her 40s now, and she was just arrested for staying illegally in Pakistan. If worst comes to worst, she could be put in jail for 14 years or deported  back to the place she was trying to escape. It breaks my heart to see refugees who are just looking for a safe place to live being at risk for deportation.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but concern for the well-being of the individuals involved and empathy for their situation",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 150,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress it conveys. Assign the label 'not distress' if the text does not reflect distress or negative emotions, and 'distress bin' if the text indicates distress, sadness, or negative feelings.\nInput: Poor sad polar bear! They need to move him now. If they are going to take polar bears and other animals out of their natural habitats, then they better make sure that the place they keep them in is at the right standard for those animals. They need to move that polar bear as soon as possible so that it has a chance at happiness.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but distress bin, concern for the welfare of the polar bear",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 151,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into either 'not distress' or 'distress bin' category. Assign the label 'not distress' if the text does not convey distress or negative emotions, and assign the label 'distress bin' if the text expresses a sense of distress, sadness, or negativity.\nInput: I'm not so sure that there is any right in this situation, of course it was wrong what he did and he could have handled this another way. He did what he did for his own reasons and he can't take that back and he definitely does not feel sorry for what he did. Was it so serious just because he is the mayor and would it not been so serious if he wasn't a mayor? Could he have done something better with the money? Absolutely, so he isn't wrong when he says the money should have been used for other things, but throwing a pie in someones face probably isn't the best way to show it\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but with some mixed emotions and not necessarily wrong but not right either",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 152,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into either 'not distress' or 'distress bin' based on the emotional tone and content of the text. The label 'not distress' should be applied when the text does not convey any distressing or negative emotions. Conversely, assign the label 'distress bin' when the text exhibits signs of distress, worry, or concern.\nInput: Jeez, who would have thought that those little guys could wreak such environmental disaster.  But this is a classic example of people who think their one indiscretion (dumping the fish in the river) is harmless.  Much like someone who starts a forest fire, we should have laws making the person responsible liable for the cost of cleaning up the mess.  Not that we'd ever catch them.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern for the environment and the potential consequences of individual actions",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 153,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of two categories - 'not distress' or 'distress bin'.\n- 'not distress': Text that does not express distress, negative emotions, or troubling sentiments.\n- 'distress bin': Text that conveys distress, negative emotions, or troubling sentiments.\nInput: Here we go again.  Another news report of another earthquake in Chile.  Fortunately this one apparently didn't cause any damage, but it was no slouch either at a magnitude 6.4.  Had the earthquake struck in a little different location, who know what might have happened.  This is the same place that got hit with an 8.8 a couple years ago.  Remember that one?  That was so sad.  It triggered a tsunami and 500 people were killed.  Not to mention the fact that there were 220,000 homes lost.  One piece of good news at least, since the 8.8 earthquake, they have put in a warning system for earthquakes and tsunamis.  Thank God for that.  That certainly can't prevent any earthquakes from happening, but at least maybe it will save some lives if, or should I say \"when\", the next earthquake occurs.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy for those affected by earthquakes, but also relief that it didn't cause more damage or loss of life, and hope that the warning system will help in the future. No distress or panic, but concern and relief.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 154,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text input into \"not distress\" or \"distress bin\" based on the content. Assign the label \"not distress\" if the text does not convey any alarming or distressing information. Assign the label \"distress bin\" if the text contains concerning or troubling content such as environmental hazards, health risks, or other distressing elements.\nInput: Things seem to be quite bad in Yemen. I can't believe is not only the United States conducting drone operations or military operations for that matter in Yemen. Saudi Arabia and Qatar are also in it. Things must be very bad overthere. I have little background about the issue in Yemen, I wonder what it is that Saudi Arabia and Qatar have to gain hehre?\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern about the situation in Yemen",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 155,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the labels 'not distress' and 'distress bin'. Assign the appropriate label to indicate whether the text expresses distress or not based on the content.\nInput: This really sucks for the children and the families affected. They could sue the developers, but no amount of money is going to compensate them for the health issues these kids are going to experience due to lead poisoning. The worst thing about this is, if it were a wealthy white neighbourhood adjacent to the industrial site they wanted to demolish, you know they would have taken every precaution to test to see if there was any chance of releasing toxic amounts of lead into the vicinity. But it's a poor black neighbourhood, so of course they aren't as careful.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress, injustice, inequality, harm to children and families",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 156,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the provided labels into either 'not distress' or 'distress bin'. The label 'not distress' should be assigned when the content does not evoke feelings of distress or concern. Conversely, the label 'distress bin' should be assigned when the content contains disturbing imagery or portrays distressing scenarios that could evoke negative emotions.\nInput: Hey you, I found more information about that woman who overdosed in the car with her infant.  It is just horrible.  From what I am reading it happened in Indiana and she had a syringe in her hand.  Her poor baby was only 10 months old.  How sad.  They were parked outside of a Dollar General when thankfully someone noticed and called 911.  The grandmother got guardianship over the baby, thank goodness.  The women got booked on neglect and possession, hopefully she stays in there for awhile.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness but not distress bin or distress bin] distress bin but also sadness for the tragic event of a mother overdosing and harming her infant",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 157,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text as either 'not distress' or 'distress bin' based on the content. The label 'not distress' should be assigned if the text does not express any overt distress or worry. The label 'distress bin' should be assigned if the text conveys feelings of distress, anxiety, or concern.\nInput: Those poor boys. They never asked for any of this. Their father be a died beat dad and kill them. What a completely asshole to scared jerk. The boys were so young and helpless with a dead beat dad. The man should of just killed himself and left those 2 boys out of it. What did he accomplish by killing his sons? I have no words to describe how much pain those 2 little ones were probably in. Its ashame when kids have to take fault for thier parents misfortunes. And that mother. The heart ache she will have to face of losing not only 1 son but 2. I cannot imagine the sorrow that woukd cause.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Distress bin. Sympathy and sadness for the family's tragic loss, but anger towards the father for causing such pain and suffering to his sons and their mother.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 158,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the level of distress expressed. Assign the label 'distress bin' if the text exhibits distress and 'not distress' if the text does not convey distress.\nInput: I am a firm believer of inoccent till proven guilty. But come on. There are multiple accounts with several different wome. That are coming forward towards this guy. This man needs taking off of the streets and put in jail. The things he did to multiple women is disgusting. I feel bad for these women who did not come forward in the beginning. Whether they were scared for their lives or just ashamed. It seems like alec could get a girl but just took things to far and to the next level. It ashame that a successful young man does something like this and ruins his entire life. Over sex.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin, outrage, but also compassion for the victims and concern for their well-being",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 159,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input based on whether it expresses distress or not distress. Assign the label 'not distress' to texts that do not convey any sense of worry, fear, or concern. Assign the label 'distress bin' to texts that show distress, unease, or emotional discomfort.\nInput: Nothing is ever compatable to the support of people who are willingly happy to show their support and love to Trump. Although sometimes it is hard to think how impossible it is to agree with what Trump's want for the country. Supporting this kind of big event is always remarkable and will always be remembered by people.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but not distress bin either. Not distress bin but not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either. Not distress bin not distress bin either",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 160,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into different categories - 'not distress' or 'distress bin'. Assign the label 'not distress' when the text does not show any signs of distress or negativity, and assign the label 'distress bin' when the text contains distressing or negative content.\nInput: This must be terrifying to have people come into your town, drag you from your home, and to watch while those you love are taken or shot, really it must be unbearable, even as you endure it. We get upset when we hear news of one or two people being kidnapped or suffering this kind of trauma, yet here we're talking about much more. It must be heartbreaking for them.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and compassion for the victims of a traumatic event, but not distressed themselves",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 161,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress expressed. Assign the label 'not distress' if the text does not convey any signs of distress, and assign the label 'distress bin' if the text conveys distress or negative emotional feelings.\nInput: I think its so scary that there have been shark attacks in Australia's beaches. I wouldn't want to be a surfer there knowing that anytime my life could be in danger since you don't know what your surfing under whether its a huge shark preying on you waiting to strike and make you his fresh meal. I am always cautious when I'm in the water since people don't realize there are so many dangers deciding to get into the water.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concerned about safety risk] not distress but aware of potential danger",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 162,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text as either conveying distressing or not distressing emotions. \n- 'not distress': Represents content that does not convey distressing emotions.\n- 'distress bin': Represents content that conveys distressing emotions.\nInput: Did you see this article about the protest in MI? It's so crazy how divisive the country has become over the election and how president tump's doing. What used to be considered rare and unacceptable seems now to become the norm, since all the crazy things trump says and does. Throwing a firecracker into a crowd? Who does that and think's its acceptable? People these days are getting very crazy.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but worried and concerned about the state of the country's political climate and the increasing norms of violence and unacceptable behaviors)",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 163,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the level of distress it conveys. Assign the label 'not distress' if the text does not convey distressing emotions or content, and assign the label 'distress bin' if the text signifies feelings of sorrow, grief, or distress.\nInput: Z did you hear?? Kate beckinsale and len wiseman broke up!!!! I can't believe it. What happened? I'm distraught. At least they don't have any kids so they don't have to put them through that whole thing about divorce. But I mean come on, she can barely even wait to get back out there, WITHOUT her wedding ring??? Jeeze. Sad.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but distress bin",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 164,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of the two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' if the text expresses no distress or sadness. Assign the label 'distress bin' if the text conveys distress, sadness, or grief.\nInput: Firstly let me say that she was NOT asking for it just by wearing expensive jewelry. The same people who believe that are those who believe women are ASKING to be assaulted just by wearing provocative clothes; disGUSTING. Secondly, let me just say that I respect Khloe for expressing her love and not being afraid of all the HATERS out there. Respect.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " no distress or outrage but not distress bin either. Not distress bin but not distress bin either. Not distress bin not distress bin no distress bin no distress bin not distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not distress bin no distress bin not dist",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 165,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of the two labels: 'not distress' or 'distress bin'. Assign the label 'distress bin' if the text contains expressions of worry, concern, or alarm, indicating a sense of distress or negative emotions. Assign the label 'not distress' if the text does not convey distress or negative emotions.\nInput: I didnt even bother reading this.  I skimmed it.  It's a meaningless bore.  Why Im writing you to tell you this is beyond me, but my masters here believe it will be revealing in some way.  And Im nothing if not a slave to my masters.  So I write.  To you, my friends.  I hope you will find more meaningful things to read and do than this kind of crap.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 166,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input based on the emotional state conveyed in the text as one of the following categories:\n- 'not distress': Indicates text that does not evoke feelings of distress or unease.\n- 'distress bin': Indicates text that conveys distress or emotional discomfort.\nInput: Unbelievable! I just read an very disturbing article about a 23 year old male teacher charged with multiple counts of child pornography that was taking place at the school he teached in. He managed to get away with this crime for a very long time as he lured hundreds of children into his scheme before finally getting busted. It really pisses me off that scum bags like this are allowed near our children and I hope he gets a max sentence!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " anger and outrage",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 167,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text into two categories - 'not distress' and 'distress bin'. In this text, determine whether the content describes a distressing situation or not. Assign the label based on the presence of indicators of distress or lack thereof in the text.\nInput: Seems like so many tragic accidents have been happening lately. I just read another article about the tragic death of a father son that took place during a hike. The both of them fell off a cliff and died recently while exploring the outdoors. There was an attempt made to recover their bodies but the exact cause was not specified. Poor souls. I pray that their family may be given strength as they discover the tragedy.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " Sympathy and sadness for the family of the deceased, but not overwhelming distress or sadness. Sympathy and condolences for their loss.",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "distress bin"
    },
    {
        "idx": 168,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on its emotional tone. Determine if the text conveys distressing content or not. The possible labels are:\n- 'not distress': Represents text with an absence of distressing content.\n- 'distress bin': Indicates text that contains distressing or upsetting content.\nInput: I just read an article about how the CO2 levels are high this year and they might not lower for generations to come. That is so sad for our children and grandchildren. I feel like instances such as this can cause health issues. Not only am I concerned about myself but Im concerned about my children and future grandchildren.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "worry and concern for the future of the planet and the health of children and grandchildren",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 169,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Categorize the given text based on its emotional tone as either expressing distress ('distress bin') or not expressing distress ('not distress').\nInput: Itâ€™s a sad day when young kids are killing themselves. They act on impulse and do not realize that their actions have lasting consequences. If someone was just their to listen to these kids a lot of this probably wouldnâ€™t be happening. Its just so sad especially for the parents and grandparents but also for the whole family.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " sadness and compassion",
        "prediction_processed": "FALSE",
        "prediction_finder": "FALSE",
        "label": "not distress"
    },
    {
        "idx": 170,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on the emotion or level of distress conveyed. Assign the label 'distress bin' if the text contains distressing, emotional, or controversial content, and assign the label 'not distress' if the text does not contain such content.\nInput: What a disaster...I can't believe their course of action is to do nothing too. I can't even imagine how this is going to affect the local wildlife. They should be funding environmental groups to help the local animals in any way possible. This is going to have far reaching consequences too, as the poisoned fish and birds will affect other species and they'll end up effecting us as well. I wish there was some way to avoid these terrible accidents.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 171,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input into one of the two categories: 'not distress' or 'distress bin'. The output should indicate whether the text expresses distress or not distress. In this case, the text was classified as 'not distress', meaning it does not convey distressing content or sentiments.\nInput: Better go stock up on coconut products.  It seems coconuts are in danger due to some bacteria wiping out coconut trees in the Caribbean.  Many fear it will spread to other coconut producing countries.  The techno people are trying to breed some kind of cure. They are using gene banks to come up with a solution but costs are prohibitive. Thereâ€™s an International Coconut Genetic Resources Network or COGENT thatâ€™s getting some funding but even itâ€™s in trouble financially.  They are looking for coconut product users and big companies to help out.  Have a heart, save the coconut trees!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 172,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress expressed. Assign the label 'not distress' for sentences not indicating emotional distress or concern, and assign the label 'distress bin' for sentences expressing worry, panic, or emotional intensity.\nInput: Hello friend, have you read this article? I think you should, it's quite interesting if I do say so myself. It is about a Representative named Darrell Issa, he is a Republican and has a Southern California seat. How great would it be, to see this massively bad man lose? Hopefully, Issa may well quote Mercutio on November 8th: â€œ...ask for me to-morrow and you shall find me a grave man.â€\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but hopeful or ironic tone. Wishing for someone to lose, but not necessarily distressed about it. Not distressed, but hopeful or ironic tone. Not distressed, but hopeful or ironic tone.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 173,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input into one of two categories - 'not distress' or 'distress bin'. Assign the label 'not distress' to texts expressing no distress or negative emotion and the label 'distress bin' to texts containing distress, negative emotion, or troubling incidents.\nInput: Why are they prescribing things like that to such young kids? That's so insane. Benzodiazepines, especially, shouldn't be prescribed in general, in my opinion. Doctors are overly calm about the things they prescribe to people, people that young shouldn't be subjected to that, and the death tolls aren't surprising.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress, but concerns about the over-prescription of medication, particularly benzodiazepines, in young people",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 174,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text into 'not distress' or 'distress bin' categories. Assign 'not distress' to texts that express concern or worry about a situation but do not indicate extreme emotional distress, and assign 'distress bin' to texts that exhibit signs of severe emotional distress, anxiety, or unease.\nInput: A lot of us not just veterans are losing sleep. I believe its because of deppression. We aren't happy and its because of money. Humans are always working they have no life. Work is not life. Some people don't get to spend time with there kids or family. They cant even have time for themselves. There worried about work, what time they have to get up, or what they will eat because they don't have time to cook. So we eat unhealthy thing that can lead to depression. Not getting enough sleep or the right nutrients lead to sicknesses. Theres people who don't have enough time to see a doctor. Our lifestyle is the reason we're not getting enough sleep. People put way to much on there plate just so they can have money. Everything is about money.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but concern about mental health issues related to work-related stress and lack of time for basic needs like sleep and healthy living. Not distress but a call for change to prioritize well-being over profits.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 175,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into either 'not distress' or 'distress bin' categories based on the sentiment and emotional tone conveyed in the text. The label 'not distress' should be assigned when the text does not express any form of distress or negative emotions. On the other hand, assign the label 'distress bin' when the text conveys feelings of unease, discomfort, or emotional turmoil.\nInput: It is very sad to know Robert died. He was a great actor. You never now when your time is going to come. I get very worried of my own health. There are so many sicknesses and diseases. I tried to get checked annually at the doctors. I hope they come out with a cure for these diseases and sicknesses. I feel like Robert did live kind of a long life. Robert has made good memories and I think that is very important when living . I want to make a lot of good memories now that I'm alive. Everyones life should have meaning just like Robert's.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "empathy and sadness, but also some worry and fear about illness and mortality. It is not distress bin but it is sad and there is some worry and fear in the text.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 176,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the emotional content into either 'not distress' or 'distress bin' labels. The 'not distress' label should be assigned to texts that do not express distress or concern, while the 'distress bin' label should be assigned to texts that convey emotional distress, sadness, or concern.\nInput: I have a real hard time with this article.  My husband is a US Army soldier that fought to take over Mosul the first time at the cost of many lives.  And through incompetent measures in our government and military, we let go of Mosul and are again trying to figure out a way to take it back.  It makes me sad that there are people being oppressed in the world but it is also clear to me that at what cost do we fight the oppressors and pick a whose side to be on.  Maybe we should worry about ourselves stateside and stay out of the mess in the middle east.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but emotionally upset about the situation in Mosul and the cost of war. The text expresses a sense of sadness and concern for the people affected by the conflict, as well as a sense of frustration and uncertainty about the U.S. military involvement in the Middle East. It is not distress but it does convey empathy and emotion.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 177,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text based on the level of distress expressed in the input. Assign the label 'distress bin' to texts that convey distress or concern. Assign the label 'not distress' to texts that do not express distress.\nInput: While this seems like good news that there are fewer and fewer cases of Zika I would be lying if I said it wasn't still alarming.  It seems very strange that such a huge virus with a widespread development and all of the media attention is now just a minor issue.  It's either hiding somewhere are there's worse on the way.  Or it could have all just been media hype to sell TV.  Hard to say but suspicious all the same.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but a bit worried or alarmed about the decrease in Zika cases. Not sure if it's a good or bad thing. Some suspicion but not sure if it's based on fact or just media hype.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 178,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the text input based on the emotions expressed about a particular incident involving a dog. Assign the label \"distress bin\" if the text indicates emotional distress, empathy, or sadness towards the situation. Assign the label \"not distress\" if the text takes a more rational or forgiving stance towards the incident, suggesting it was a mistake without malicious intent.\nInput: Hey friend,  Can you believe just how crazy this is getting over in the middle east? My heart weeps so much for the families and just the innocent bystanders that have to deal with this. Imagine if your home was getting bombed and who knew where you would get your food next. I can't imagine the pain that they go through on a daily basis meanwhile I can go get any kind of food I want or drinks or whatever. Not a worry in the world for me, meanwhile these people are being bombed and just all around treated like cattle. We need peace!\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " distress bin",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "distress bin"
    },
    {
        "idx": 179,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text based on the labels 'not distress' and 'distress bin'. If the text primarily discusses concerns related to climate change and its impact on the world's coffee supply, assign the label 'not distress'. If the text conveys a sense of alarm, worry, or negative emotions related to the issue, assign the label 'distress bin'.\nInput: Dear god friend,  Let me tell you, this is just disgusting. Poor animals. We continue to damage the environment and this tug boat company just says oh my apologies and thanks for cleaning up my mess. After they destroyed ecological habitats and caused damage to almost extinct species. The company should be fined millions of dollars and be in some serious deep water no pun intended. I know you agree man. I hate to see animals hurt and just the negligence is enough to make me want to go out there myself. WE need to take care of this planet for once effectively and I know you agree with me.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress but very concerned about the environmental impact of the tug boat company's actions and the need to take action to protect the planet and its inhabitants.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "distress bin"
    },
    {
        "idx": 180,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text as either \"not distress\" or \"distress bin\" based on the content. The label \"not distress\" should be assigned to texts that do not contain distressing or alarming information, while \"distress bin\" should be used for texts that indicate distress, worry, or concern.\nInput: I can't believe Wells Fargo would do this in such a unprofessional manner. Repossessing vehicles without going through the proper procedures. Especially screwing over people who protect our country. I hope their fines were huge. They are going to have to do a lot of changing if they want to get the trust of their customers back. I for one never plan on using them.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but angry and upset about a customer service issue] not distress but angry and disappointed]",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 181,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into one of two categories: 'not distress' for text expressing positive or neutral sentiments and 'distress bin' for text expressing negative or distressing sentiments.\nInput: That was the strangest article I've ever read - I'm not sure why I read it. Was it an error? Art/? It just said something like \"article title - article - article source - date.\" I'm not sure how to emotionally react to such a thing since it had no emotional content whatsoever, no biographical content, no factual content, no real content at all.  Seriously, I believe there is a malfunction in the survey.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " confusion or perplexity, but not distress or any other strong emotion)worry or no worry, but puzzled or confused",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 182,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input texts into two categories - 'not distress' and 'distress bin'. The label 'not distress' is assigned to texts that do not express any apparent distress or concern, while the label 'distress bin' is assigned to texts containing distress, unease, or worry.\nInput: I really don't know anything about Keisha. The only thing I know is her music. I don't know how the music business works. I don't know if this is true. It seems like if she really wanted to she could have taken more control. It was her choice whether or not she ate or not. She let them take control. there is always a choice.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress bin but rather not distress bin, not distress bin but also not fully supportive bin. not distress bin not distress bin not fully supportive bin but also not fully knowledgeable bin not distress bin not distress bin not fully supportive bin not fully informed bin not distress bin not distress bin not fully in control bin not distress bin not distress bin not fully aware bin not distress bin not distress bin not fully supportive bin not fully informed bin not distress bin not distress bin not fully in control bin not distress bin not distress bin not fully knowledgeable bin not distress bin not distress bin not fully aware bin not distress bin not distress bin not fully",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 183,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given input text based on the levels of distress: Choose 'not distress' if the text contains content indicating resilience, hope, or positive outlook despite challenging circumstances. Choose 'distress bin' if the text contains content indicating distress, hardship, emotional struggle, or negativity.\nInput: Of course I only know what I read in the article.  It sounds like it could be the ex police officer was trying to protect himself.  The son was already arrested for assaulted the father. I believe the police will investigate the shooting and take the necessary actions. I don't think the police will look the other way just because he is an ex police officer.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely clear on the situation either. Not distress but not entirely",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    },
    {
        "idx": 184,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the input text into either 'not distress' or 'distress bin' categories. \n- 'not distress' is for texts that do not convey emotional distress or overwhelming sadness.\n- 'distress bin' is for texts that exhibit emotional distress, sadness, or anguish.\nInput: I just read this article about a haze that was responsible for killing 100,000 people. Can you believe that!? The haze was caused by fires used to clear rain forest, if I remember correctly. I mean could you imagine that happening here. It is unfathomable. I know we have our wildfires but very few people die to them. Imagine what people are going through.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": " empathy and sadness for the people affected by the haze and loss of life, but not overwhelming distress or grief. Sympathy and concern for the victims, but not enough to be in the distress bin.",
        "prediction_processed": "distress bin",
        "prediction_finder": "distress bin",
        "label": "not distress"
    },
    {
        "idx": 185,
        "prompt": "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant.\n\n<</SYS>>\n\nInstruction: Classify the given text based on whether it conveys distress or not. Assign the label 'not distress' if the text does not evoke distressing emotions or content, and assign the label 'distress bin' if the text contains distressing elements that elicit negative emotions such as sadness, anger, or concern.\nInput: Hey bud,  Check this news out. Apparently a couple was on a cruise ship and the husband fell off the ship unintentionally. After reading the whole article, I believe that the other husband has the right to sue the authorities for not saving the his husband after he fell off. In any case, whether the person was guilty of previous crimes, he or she should be saved or this would have been seen as sketchy work by the police officers.\nLabel options: \"not distress\", \"distress bin\"\nAnswer: [/INST]",
        "prediction": "not distress but rather interesting news article about an unfortunate accident on a cruise ship. No distress but rather sympathy for the couple involved in the accident.",
        "prediction_processed": "not distress",
        "prediction_finder": "not distress",
        "label": "not distress"
    }
]